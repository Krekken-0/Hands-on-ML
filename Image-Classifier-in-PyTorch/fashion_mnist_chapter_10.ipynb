{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "497e1252",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torchvision\n",
    "import torchvision.transforms.v2 as T\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchmetrics\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "79f95f2f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2.9.1+cu128'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b284f0aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "toTensor = T.Compose([T.ToImage(), T.ToDtype(torch.float32, scale=True)])\n",
    "\n",
    "train_and_valid_data = torchvision.datasets.FashionMNIST(\n",
    "    root=\"dataset\", train=True, transform=toTensor,download=True\n",
    ")\n",
    "\n",
    "test_data = torchvision.datasets.FashionMNIST(\n",
    "    root=\"dataset\", train=False, transform=toTensor, download=True\n",
    ")\n",
    "\n",
    "torch.manual_seed(42)\n",
    "train_data, valid_data = torch.utils.data.random_split(\n",
    "    train_and_valid_data, [55000, 5000]\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "58086f43",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "train_loader = DataLoader(train_data, batch_size=32, shuffle=True)\n",
    "valid_loader = DataLoader(valid_data, batch_size=32)\n",
    "test_loader = DataLoader(test_data, batch_size=32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b213017c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([1, 28, 28]), torch.float32)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_sample, y_sample = train_data[0]\n",
    "X_sample.shape, X_sample.dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4d3e6f82",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['T-shirt/top',\n",
       " 'Trouser',\n",
       " 'Pullover',\n",
       " 'Dress',\n",
       " 'Coat',\n",
       " 'Sandal',\n",
       " 'Shirt',\n",
       " 'Sneaker',\n",
       " 'Bag',\n",
       " 'Ankle boot']"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_and_valid_data.classes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0fee4d59",
   "metadata": {},
   "source": [
    "#### Building the Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "05062c29",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ImageClassifier(nn.Module):\n",
    "    def __init__(self, n_inputs, n_hidden1, n_hidden2, n_classes):\n",
    "        super().__init__()\n",
    "        self.mlp = nn.Sequential(\n",
    "            nn.Flatten(),\n",
    "            nn.Linear(n_inputs, n_hidden1),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(n_hidden1, n_hidden2),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(n_hidden2, n_classes)\n",
    "        )\n",
    "\n",
    "    def forward(self, X):\n",
    "        return self.mlp(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4c42c8e7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'cuda'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b7521711",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.manual_seed(42)\n",
    "model = ImageClassifier(n_inputs=1*28*28, n_hidden1=300, n_hidden2=100,\n",
    "                        n_classes=10).to(device)\n",
    "\n",
    "xentropy = nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "071ae1d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torchmetrics\n",
    "\n",
    "def evaluate_tm(model, data_Loader, metric):\n",
    "    model.eval()\n",
    "    metric.reset()\n",
    "    with torch.inference_mode():\n",
    "        for X_batch, y_batch in data_Loader:\n",
    "            X_batch, y_batch = X_batch.to(device), y_batch.to(device)\n",
    "            y_pred = model(X_batch)\n",
    "            metric.update(y_pred, y_batch)\n",
    "    return metric.compute()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "f4d4af8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train2(model, optimizer, criterion, metric, train_loader, valid_loader, n_epochs):\n",
    "    history = {\"train_losses\":[],\n",
    "               \"train_metrics\":[],\n",
    "               \"valid_metrics\": []}\n",
    "    for epoch in range(n_epochs):\n",
    "        total_loss = 0.\n",
    "        metric.reset()\n",
    "        for X_batch, y_batch in train_loader:\n",
    "            model.train()\n",
    "            X_batch, y_batch = X_batch.to(device), y_batch.to(device)\n",
    "            y_pred = model(X_batch)\n",
    "            loss = criterion(y_pred, y_batch)\n",
    "            total_loss += loss.item()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            optimizer.zero_grad()\n",
    "            metric(y_pred, y_batch)\n",
    "        mean_loss = total_loss / len(train_loader)\n",
    "        history[\"train_losses\"].append(mean_loss)\n",
    "        history[\"train_metrics\"].append(metric.compute().item())\n",
    "        history[\"valid_metrics\"].append(evaluate_tm(model, valid_loader, metric).item())\n",
    "\n",
    "        print(f\"Epoch: {epoch+1}/{n_epochs},\",\n",
    "              f\"Train Loss: {history[\"train_losses\"][-1]:.4f}\",\n",
    "              f\"Train metric: {history[\"train_metrics\"][-1]:.4f}\",\n",
    "              f\"Valid Metrics: {history[\"valid_metrics\"][-1]:.4f}\",\n",
    "              f\"Total Loss: {total_loss:.4f}\",\n",
    "              f\"Loss.item(): {loss}\"\n",
    "              )\n",
    "    return history\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a6c87b2",
   "metadata": {},
   "source": [
    "Un comment the line to train the model and see metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b99f1b34",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = torch.optim.SGD(model.parameters(), lr = 0.1)\n",
    "accuracy = torchmetrics.Accuracy(task=\"multiclass\", num_classes=10).to(device)\n",
    "n_epochs = 20\n",
    "# _ = train2(model, optimizer, xentropy, accuracy, train_loader, valid_loader, n_epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "7778f22e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([5, 5, 5], device='cuda:0')"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.eval()\n",
    "X_new, y_new = next(iter(valid_loader))\n",
    "X_new = X_new[:3].to(device)\n",
    "with torch.inference_mode():\n",
    "    y_pred_logits = model(X_new)\n",
    "y_pred = y_pred_logits.argmax(dim = 1)\n",
    "y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "ce77b370",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Sandal', 'Sandal', 'Sandal']"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[train_and_valid_data.classes[idx] for idx in y_pred]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "d3cf429b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([7, 4, 2])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_new[:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "20aed294",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.1040, 0.1010, 0.0960, 0.0950, 0.1010, 0.1060, 0.1010, 0.0930, 0.0990,\n",
       "         0.1030],\n",
       "        [0.1020, 0.1000, 0.0990, 0.0970, 0.0930, 0.1150, 0.1000, 0.0960, 0.1000,\n",
       "         0.0970],\n",
       "        [0.1010, 0.1040, 0.0990, 0.0920, 0.0940, 0.1160, 0.0970, 0.0970, 0.1010,\n",
       "         0.0990]], device='cuda:0')"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch.nn.functional as F\n",
    "y_proba = F.softmax(y_pred_logits, dim = 1)\n",
    "if device == \"mps\":\n",
    "    y_proba = y_proba.cpu()\n",
    "y_proba.round(decimals=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "ce941ba4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.2550, 0.2510, 0.2490, 0.2440],\n",
       "        [0.2750, 0.2450, 0.2400, 0.2400],\n",
       "        [0.2740, 0.2470, 0.2400, 0.2390]], device='cuda:0')"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_top4_logits, y_top4_indices = torch.topk(y_pred_logits, k = 4, dim = 1)\n",
    "y_top4_proba = F.softmax(y_top4_logits, dim = 1)\n",
    "y_top4_proba.round(decimals = 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "facadf90",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[5, 0, 9, 1],\n",
       "        [5, 0, 1, 6],\n",
       "        [5, 1, 0, 8]], device='cuda:0')"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_top4_indices"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de939076",
   "metadata": {},
   "source": [
    "### Fine-tuning Hyperparameters with optuna"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "4212f4da",
   "metadata": {},
   "outputs": [],
   "source": [
    "import optuna\n",
    "\n",
    "def objective(trial, train_loader, valid_loader):\n",
    "    learning_rate = trial.suggest_float(\"learning_rate\", 1e-5, 1e-1, log = True)\n",
    "    n_hidden = trial.suggest_int(\"n_hidden\", 20, 300)\n",
    "    model = ImageClassifier(n_inputs=1*28*28,n_hidden1=n_hidden,\n",
    "                            n_hidden2=n_hidden,n_classes=10).to(device)\n",
    "    optimizer = torch.optim.SGD(model.parameters(), lr = learning_rate)\n",
    "    xentropy = nn.CrossEntropyLoss()\n",
    "    accuracy = torchmetrics.Accuracy(task = \"multiclass\", num_classes=10)\n",
    "    accuracy = accuracy.to(device)\n",
    "    best_validation_accuracy = 0.\n",
    "    \n",
    "    for epoch in range(n_epochs):\n",
    "        history = train2(model, optimizer, xentropy, accuracy, train_loader,\n",
    "                     valid_loader, n_epochs=1)\n",
    "        validation_accuracy = max(history[\"valid_metrics\"])\n",
    "        if validation_accuracy > best_validation_accuracy:\n",
    "            best_validation_accuracy = validation_accuracy\n",
    "        trial.report(validation_accuracy, epoch)\n",
    "\n",
    "        if trial.should_prune():\n",
    "            raise optuna.TrialPruned\n",
    "    \n",
    "    return best_validation_accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "c9498dbb",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2026-01-09 16:12:07,688] A new study created in memory with name: no-name-679b7a6b-09dc-49ea-ba53-c0d0a64b1ee7\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1/1, Train Loss: 2.2769 Train metric: 0.1471 Valid Metrics: 0.1860\n",
      "Epoch: 1/1, Train Loss: 2.2093 Train metric: 0.2794 Valid Metrics: 0.3500\n",
      "Epoch: 1/1, Train Loss: 2.1164 Train metric: 0.4109 Valid Metrics: 0.4554\n",
      "Epoch: 1/1, Train Loss: 1.9776 Train metric: 0.5137 Valid Metrics: 0.5560\n",
      "Epoch: 1/1, Train Loss: 1.7867 Train metric: 0.5826 Valid Metrics: 0.6026\n",
      "Epoch: 1/1, Train Loss: 1.5775 Train metric: 0.6184 Valid Metrics: 0.6228\n",
      "Epoch: 1/1, Train Loss: 1.3978 Train metric: 0.6288 Valid Metrics: 0.6326\n",
      "Epoch: 1/1, Train Loss: 1.2605 Train metric: 0.6360 Valid Metrics: 0.6372\n",
      "Epoch: 1/1, Train Loss: 1.1572 Train metric: 0.6467 Valid Metrics: 0.6424\n",
      "Epoch: 1/1, Train Loss: 1.0782 Train metric: 0.6537 Valid Metrics: 0.6436\n",
      "Epoch: 1/1, Train Loss: 1.0162 Train metric: 0.6611 Valid Metrics: 0.6530\n",
      "Epoch: 1/1, Train Loss: 0.9665 Train metric: 0.6689 Valid Metrics: 0.6620\n",
      "Epoch: 1/1, Train Loss: 0.9258 Train metric: 0.6761 Valid Metrics: 0.6700\n",
      "Epoch: 1/1, Train Loss: 0.8919 Train metric: 0.6835 Valid Metrics: 0.6782\n",
      "Epoch: 1/1, Train Loss: 0.8629 Train metric: 0.6897 Valid Metrics: 0.6848\n",
      "Epoch: 1/1, Train Loss: 0.8381 Train metric: 0.6954 Valid Metrics: 0.6876\n",
      "Epoch: 1/1, Train Loss: 0.8166 Train metric: 0.7009 Valid Metrics: 0.6932\n",
      "Epoch: 1/1, Train Loss: 0.7974 Train metric: 0.7073 Valid Metrics: 0.6964\n",
      "Epoch: 1/1, Train Loss: 0.7802 Train metric: 0.7119 Valid Metrics: 0.7090\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2026-01-09 16:14:03,657] Trial 0 finished with value: 0.7089999914169312 and parameters: {'learning_rate': 0.00031489116479568613, 'n_hidden': 287}. Best is trial 0 with value: 0.7089999914169312.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1/1, Train Loss: 0.7647 Train metric: 0.7196 Valid Metrics: 0.7082\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[W 2026-01-09 16:14:04,596] Trial 1 failed with parameters: {'learning_rate': 0.008471801418819975, 'n_hidden': 188} because of the following error: KeyboardInterrupt().\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/krekken/Hands-on-ML/env/lib/python3.12/site-packages/optuna/study/_optimize.py\", line 205, in _run_trial\n",
      "    value_or_values = func(trial)\n",
      "                      ^^^^^^^^^^^\n",
      "  File \"/tmp/ipykernel_9915/4164084884.py\", line 3, in <lambda>\n",
      "    objective_with_data = lambda trial: objective(\n",
      "                                        ^^^^^^^^^^\n",
      "  File \"/tmp/ipykernel_9915/1814299302.py\", line 15, in objective\n",
      "    history = train2(model, optimizer, xentropy, accuracy, train_loader,\n",
      "              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/tmp/ipykernel_9915/3590758802.py\", line 8, in train2\n",
      "    for X_batch, y_batch in train_loader:\n",
      "  File \"/home/krekken/Hands-on-ML/env/lib/python3.12/site-packages/torch/utils/data/dataloader.py\", line 732, in __next__\n",
      "    data = self._next_data()\n",
      "           ^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/krekken/Hands-on-ML/env/lib/python3.12/site-packages/torch/utils/data/dataloader.py\", line 788, in _next_data\n",
      "    data = self._dataset_fetcher.fetch(index)  # may raise StopIteration\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/krekken/Hands-on-ML/env/lib/python3.12/site-packages/torch/utils/data/_utils/fetch.py\", line 50, in fetch\n",
      "    data = self.dataset.__getitems__(possibly_batched_index)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/krekken/Hands-on-ML/env/lib/python3.12/site-packages/torch/utils/data/dataset.py\", line 416, in __getitems__\n",
      "    return [self.dataset[self.indices[idx]] for idx in indices]\n",
      "            ~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/krekken/Hands-on-ML/env/lib/python3.12/site-packages/torchvision/datasets/mnist.py\", line 139, in __getitem__\n",
      "    img, target = self.data[index], int(self.targets[index])\n",
      "                                    ^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "KeyboardInterrupt\n",
      "[W 2026-01-09 16:14:04,604] Trial 1 failed with value None.\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[20]\u001b[39m\u001b[32m, line 9\u001b[39m\n\u001b[32m      6\u001b[39m pruner = optuna.pruners.MedianPruner(n_min_trials=\u001b[32m5\u001b[39m, n_warmup_steps=\u001b[32m0\u001b[39m,\n\u001b[32m      7\u001b[39m                                      interval_steps=\u001b[32m1\u001b[39m)\n\u001b[32m      8\u001b[39m study = optuna.create_study(direction=\u001b[33m\"\u001b[39m\u001b[33mmaximize\u001b[39m\u001b[33m\"\u001b[39m, sampler=sampler, pruner=pruner)\n\u001b[32m----> \u001b[39m\u001b[32m9\u001b[39m \u001b[43mstudy\u001b[49m\u001b[43m.\u001b[49m\u001b[43moptimize\u001b[49m\u001b[43m(\u001b[49m\u001b[43mobjective_with_data\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_trials\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m5\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Hands-on-ML/env/lib/python3.12/site-packages/optuna/study/study.py:490\u001b[39m, in \u001b[36mStudy.optimize\u001b[39m\u001b[34m(self, func, n_trials, timeout, n_jobs, catch, callbacks, gc_after_trial, show_progress_bar)\u001b[39m\n\u001b[32m    388\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34moptimize\u001b[39m(\n\u001b[32m    389\u001b[39m     \u001b[38;5;28mself\u001b[39m,\n\u001b[32m    390\u001b[39m     func: ObjectiveFuncType,\n\u001b[32m   (...)\u001b[39m\u001b[32m    397\u001b[39m     show_progress_bar: \u001b[38;5;28mbool\u001b[39m = \u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[32m    398\u001b[39m ) -> \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m    399\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"Optimize an objective function.\u001b[39;00m\n\u001b[32m    400\u001b[39m \n\u001b[32m    401\u001b[39m \u001b[33;03m    Optimization is done by choosing a suitable set of hyperparameter values from a given\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m    488\u001b[39m \u001b[33;03m            If nested invocation of this method occurs.\u001b[39;00m\n\u001b[32m    489\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m490\u001b[39m     \u001b[43m_optimize\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    491\u001b[39m \u001b[43m        \u001b[49m\u001b[43mstudy\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m    492\u001b[39m \u001b[43m        \u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m=\u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    493\u001b[39m \u001b[43m        \u001b[49m\u001b[43mn_trials\u001b[49m\u001b[43m=\u001b[49m\u001b[43mn_trials\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    494\u001b[39m \u001b[43m        \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    495\u001b[39m \u001b[43m        \u001b[49m\u001b[43mn_jobs\u001b[49m\u001b[43m=\u001b[49m\u001b[43mn_jobs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    496\u001b[39m \u001b[43m        \u001b[49m\u001b[43mcatch\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mtuple\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mcatch\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43misinstance\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mcatch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mIterable\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43mcatch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    497\u001b[39m \u001b[43m        \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    498\u001b[39m \u001b[43m        \u001b[49m\u001b[43mgc_after_trial\u001b[49m\u001b[43m=\u001b[49m\u001b[43mgc_after_trial\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    499\u001b[39m \u001b[43m        \u001b[49m\u001b[43mshow_progress_bar\u001b[49m\u001b[43m=\u001b[49m\u001b[43mshow_progress_bar\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    500\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Hands-on-ML/env/lib/python3.12/site-packages/optuna/study/_optimize.py:67\u001b[39m, in \u001b[36m_optimize\u001b[39m\u001b[34m(study, func, n_trials, timeout, n_jobs, catch, callbacks, gc_after_trial, show_progress_bar)\u001b[39m\n\u001b[32m     65\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m     66\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m n_jobs == \u001b[32m1\u001b[39m:\n\u001b[32m---> \u001b[39m\u001b[32m67\u001b[39m         \u001b[43m_optimize_sequential\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m     68\u001b[39m \u001b[43m            \u001b[49m\u001b[43mstudy\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     69\u001b[39m \u001b[43m            \u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     70\u001b[39m \u001b[43m            \u001b[49m\u001b[43mn_trials\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     71\u001b[39m \u001b[43m            \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     72\u001b[39m \u001b[43m            \u001b[49m\u001b[43mcatch\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     73\u001b[39m \u001b[43m            \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     74\u001b[39m \u001b[43m            \u001b[49m\u001b[43mgc_after_trial\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     75\u001b[39m \u001b[43m            \u001b[49m\u001b[43mreseed_sampler_rng\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m     76\u001b[39m \u001b[43m            \u001b[49m\u001b[43mtime_start\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m     77\u001b[39m \u001b[43m            \u001b[49m\u001b[43mprogress_bar\u001b[49m\u001b[43m=\u001b[49m\u001b[43mprogress_bar\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     78\u001b[39m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     79\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m     80\u001b[39m         \u001b[38;5;28;01mif\u001b[39;00m n_jobs == -\u001b[32m1\u001b[39m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Hands-on-ML/env/lib/python3.12/site-packages/optuna/study/_optimize.py:164\u001b[39m, in \u001b[36m_optimize_sequential\u001b[39m\u001b[34m(study, func, n_trials, timeout, catch, callbacks, gc_after_trial, reseed_sampler_rng, time_start, progress_bar)\u001b[39m\n\u001b[32m    161\u001b[39m         \u001b[38;5;28;01mbreak\u001b[39;00m\n\u001b[32m    163\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m164\u001b[39m     frozen_trial_id = \u001b[43m_run_trial\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstudy\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcatch\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    165\u001b[39m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[32m    166\u001b[39m     \u001b[38;5;66;03m# The following line mitigates memory problems that can be occurred in some\u001b[39;00m\n\u001b[32m    167\u001b[39m     \u001b[38;5;66;03m# environments (e.g., services that use computing containers such as GitHub Actions).\u001b[39;00m\n\u001b[32m    168\u001b[39m     \u001b[38;5;66;03m# Please refer to the following PR for further details:\u001b[39;00m\n\u001b[32m    169\u001b[39m     \u001b[38;5;66;03m# https://github.com/optuna/optuna/pull/325.\u001b[39;00m\n\u001b[32m    170\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m gc_after_trial:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Hands-on-ML/env/lib/python3.12/site-packages/optuna/study/_optimize.py:262\u001b[39m, in \u001b[36m_run_trial\u001b[39m\u001b[34m(study, func, catch)\u001b[39m\n\u001b[32m    255\u001b[39m         \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28;01mFalse\u001b[39;00m, \u001b[33m\"\u001b[39m\u001b[33mShould not reach.\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    257\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[32m    258\u001b[39m     updated_state == TrialState.FAIL\n\u001b[32m    259\u001b[39m     \u001b[38;5;129;01mand\u001b[39;00m func_err \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m    260\u001b[39m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(func_err, catch)\n\u001b[32m    261\u001b[39m ):\n\u001b[32m--> \u001b[39m\u001b[32m262\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m func_err\n\u001b[32m    263\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m trial._trial_id\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Hands-on-ML/env/lib/python3.12/site-packages/optuna/study/_optimize.py:205\u001b[39m, in \u001b[36m_run_trial\u001b[39m\u001b[34m(study, func, catch)\u001b[39m\n\u001b[32m    203\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m get_heartbeat_thread(trial._trial_id, study._storage):\n\u001b[32m    204\u001b[39m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m205\u001b[39m         value_or_values = \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrial\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    206\u001b[39m     \u001b[38;5;28;01mexcept\u001b[39;00m exceptions.TrialPruned \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m    207\u001b[39m         \u001b[38;5;66;03m# TODO(mamu): Handle multi-objective cases.\u001b[39;00m\n\u001b[32m    208\u001b[39m         state = TrialState.PRUNED\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[20]\u001b[39m\u001b[32m, line 3\u001b[39m, in \u001b[36m<lambda>\u001b[39m\u001b[34m(trial)\u001b[39m\n\u001b[32m      1\u001b[39m torch.manual_seed(\u001b[32m42\u001b[39m)\n\u001b[32m      2\u001b[39m sampler = optuna.samplers.TPESampler(seed=\u001b[32m42\u001b[39m)\n\u001b[32m----> \u001b[39m\u001b[32m3\u001b[39m objective_with_data = \u001b[38;5;28;01mlambda\u001b[39;00m trial: \u001b[43mobjective\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m      4\u001b[39m \u001b[43m    \u001b[49m\u001b[43mtrial\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalid_loader\u001b[49m\n\u001b[32m      5\u001b[39m \u001b[43m)\u001b[49m\n\u001b[32m      6\u001b[39m pruner = optuna.pruners.MedianPruner(n_min_trials=\u001b[32m5\u001b[39m, n_warmup_steps=\u001b[32m0\u001b[39m,\n\u001b[32m      7\u001b[39m                                      interval_steps=\u001b[32m1\u001b[39m)\n\u001b[32m      8\u001b[39m study = optuna.create_study(direction=\u001b[33m\"\u001b[39m\u001b[33mmaximize\u001b[39m\u001b[33m\"\u001b[39m, sampler=sampler, pruner=pruner)\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[19]\u001b[39m\u001b[32m, line 15\u001b[39m, in \u001b[36mobjective\u001b[39m\u001b[34m(trial, train_loader, valid_loader)\u001b[39m\n\u001b[32m     12\u001b[39m best_validation_accuracy = \u001b[32m0.\u001b[39m\n\u001b[32m     14\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m epoch \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(n_epochs):\n\u001b[32m---> \u001b[39m\u001b[32m15\u001b[39m     history = \u001b[43mtrain2\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mxentropy\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maccuracy\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_loader\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     16\u001b[39m \u001b[43m                 \u001b[49m\u001b[43mvalid_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_epochs\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m1\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m     17\u001b[39m     validation_accuracy = \u001b[38;5;28mmax\u001b[39m(history[\u001b[33m\"\u001b[39m\u001b[33mvalid_metrics\u001b[39m\u001b[33m\"\u001b[39m])\n\u001b[32m     18\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m validation_accuracy > best_validation_accuracy:\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[11]\u001b[39m\u001b[32m, line 8\u001b[39m, in \u001b[36mtrain2\u001b[39m\u001b[34m(model, optimizer, criterion, metric, train_loader, valid_loader, n_epochs)\u001b[39m\n\u001b[32m      6\u001b[39m total_loss = \u001b[32m0.\u001b[39m\n\u001b[32m      7\u001b[39m metric.reset()\n\u001b[32m----> \u001b[39m\u001b[32m8\u001b[39m \u001b[43m\u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mX_batch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_batch\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mtrain_loader\u001b[49m\u001b[43m:\u001b[49m\n\u001b[32m      9\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m.\u001b[49m\u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     10\u001b[39m \u001b[43m    \u001b[49m\u001b[43mX_batch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_batch\u001b[49m\u001b[43m \u001b[49m\u001b[43m=\u001b[49m\u001b[43m \u001b[49m\u001b[43mX_batch\u001b[49m\u001b[43m.\u001b[49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_batch\u001b[49m\u001b[43m.\u001b[49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Hands-on-ML/env/lib/python3.12/site-packages/torch/utils/data/dataloader.py:732\u001b[39m, in \u001b[36m_BaseDataLoaderIter.__next__\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    729\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m._sampler_iter \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m    730\u001b[39m     \u001b[38;5;66;03m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[39;00m\n\u001b[32m    731\u001b[39m     \u001b[38;5;28mself\u001b[39m._reset()  \u001b[38;5;66;03m# type: ignore[call-arg]\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m732\u001b[39m data = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_next_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    733\u001b[39m \u001b[38;5;28mself\u001b[39m._num_yielded += \u001b[32m1\u001b[39m\n\u001b[32m    734\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[32m    735\u001b[39m     \u001b[38;5;28mself\u001b[39m._dataset_kind == _DatasetKind.Iterable\n\u001b[32m    736\u001b[39m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m._IterableDataset_len_called \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m    737\u001b[39m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m._num_yielded > \u001b[38;5;28mself\u001b[39m._IterableDataset_len_called\n\u001b[32m    738\u001b[39m ):\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Hands-on-ML/env/lib/python3.12/site-packages/torch/utils/data/dataloader.py:788\u001b[39m, in \u001b[36m_SingleProcessDataLoaderIter._next_data\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    786\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m_next_data\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[32m    787\u001b[39m     index = \u001b[38;5;28mself\u001b[39m._next_index()  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m788\u001b[39m     data = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_dataset_fetcher\u001b[49m\u001b[43m.\u001b[49m\u001b[43mfetch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mindex\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[32m    789\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m._pin_memory:\n\u001b[32m    790\u001b[39m         data = _utils.pin_memory.pin_memory(data, \u001b[38;5;28mself\u001b[39m._pin_memory_device)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Hands-on-ML/env/lib/python3.12/site-packages/torch/utils/data/_utils/fetch.py:50\u001b[39m, in \u001b[36m_MapDatasetFetcher.fetch\u001b[39m\u001b[34m(self, possibly_batched_index)\u001b[39m\n\u001b[32m     48\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.auto_collation:\n\u001b[32m     49\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(\u001b[38;5;28mself\u001b[39m.dataset, \u001b[33m\"\u001b[39m\u001b[33m__getitems__\u001b[39m\u001b[33m\"\u001b[39m) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m.dataset.__getitems__:\n\u001b[32m---> \u001b[39m\u001b[32m50\u001b[39m         data = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mdataset\u001b[49m\u001b[43m.\u001b[49m\u001b[43m__getitems__\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpossibly_batched_index\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     51\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m     52\u001b[39m         data = [\u001b[38;5;28mself\u001b[39m.dataset[idx] \u001b[38;5;28;01mfor\u001b[39;00m idx \u001b[38;5;129;01min\u001b[39;00m possibly_batched_index]\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Hands-on-ML/env/lib/python3.12/site-packages/torch/utils/data/dataset.py:416\u001b[39m, in \u001b[36mSubset.__getitems__\u001b[39m\u001b[34m(self, indices)\u001b[39m\n\u001b[32m    414\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m.dataset.__getitems__([\u001b[38;5;28mself\u001b[39m.indices[idx] \u001b[38;5;28;01mfor\u001b[39;00m idx \u001b[38;5;129;01min\u001b[39;00m indices])  \u001b[38;5;66;03m# type: ignore[attr-defined]\u001b[39;00m\n\u001b[32m    415\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m416\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m [\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mdataset\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mindices\u001b[49m\u001b[43m[\u001b[49m\u001b[43midx\u001b[49m\u001b[43m]\u001b[49m\u001b[43m]\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m idx \u001b[38;5;129;01min\u001b[39;00m indices]\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Hands-on-ML/env/lib/python3.12/site-packages/torchvision/datasets/mnist.py:139\u001b[39m, in \u001b[36mMNIST.__getitem__\u001b[39m\u001b[34m(self, index)\u001b[39m\n\u001b[32m    131\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m__getitem__\u001b[39m(\u001b[38;5;28mself\u001b[39m, index: \u001b[38;5;28mint\u001b[39m) -> \u001b[38;5;28mtuple\u001b[39m[Any, Any]:\n\u001b[32m    132\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m    133\u001b[39m \u001b[33;03m    Args:\u001b[39;00m\n\u001b[32m    134\u001b[39m \u001b[33;03m        index (int): Index\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m    137\u001b[39m \u001b[33;03m        tuple: (image, target) where target is index of the target class.\u001b[39;00m\n\u001b[32m    138\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m139\u001b[39m     img, target = \u001b[38;5;28mself\u001b[39m.data[index], \u001b[38;5;28;43mint\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mtargets\u001b[49m\u001b[43m[\u001b[49m\u001b[43mindex\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    141\u001b[39m     \u001b[38;5;66;03m# doing this so that it is consistent with all other datasets\u001b[39;00m\n\u001b[32m    142\u001b[39m     \u001b[38;5;66;03m# to return a PIL Image\u001b[39;00m\n\u001b[32m    143\u001b[39m     img = _Image_fromarray(img.numpy(), mode=\u001b[33m\"\u001b[39m\u001b[33mL\u001b[39m\u001b[33m\"\u001b[39m)\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "torch.manual_seed(42)\n",
    "sampler = optuna.samplers.TPESampler(seed=42)\n",
    "objective_with_data = lambda trial: objective(\n",
    "    trial, train_loader, valid_loader\n",
    ")\n",
    "pruner = optuna.pruners.MedianPruner(n_min_trials=5, n_warmup_steps=0,\n",
    "                                     interval_steps=1)\n",
    "study = optuna.create_study(direction=\"maximize\", sampler=sampler, pruner=pruner)\n",
    "study.optimize(objective_with_data, n_trials=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac25d361",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'learning_rate': 0.008471801418819975, 'n_hidden': 188}"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "study.best_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4481e3d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8677999973297119"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "study.best_value"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4102cae",
   "metadata": {},
   "source": [
    "### Saving and loading PyTroch models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "815236b3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.save(model.state_dict(), \"my_fashion_mnist_weights.pt\")\n",
    "new_model = ImageClassifier(n_inputs=1*28*28, n_hidden1 = 300, n_hidden2 = 100,\n",
    "                            n_classes = 10)\n",
    "loaded_weights = torch.load(\"my_fashion_mnist_weights.pt\", weights_only=True)\n",
    "new_model.load_state_dict(loaded_weights)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea5b6712",
   "metadata": {},
   "source": [
    "#### Compiling and Optimizing a PyTroch model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "faa52053",
   "metadata": {},
   "outputs": [],
   "source": [
    "torchscript_model = torch.jit.trace(model, X_new)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9f15d9f",
   "metadata": {},
   "source": [
    "### Exercises"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5616f66d",
   "metadata": {},
   "source": [
    "13"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "cdeae6c6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1.489864706993103, 0.26291730999946594)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = torch.tensor([1.2], requires_grad=True)\n",
    "y = torch.tensor([3.4], requires_grad=True)\n",
    "\n",
    "def f(x,y):\n",
    "    return torch.sin((x**2) * y)\n",
    "\n",
    "result = f(x,y)\n",
    "result.backward()\n",
    "\n",
    "x.grad.item(), y.grad.item()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09f1c46a",
   "metadata": {},
   "source": [
    "14"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "fe57f21c",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Dense2(nn.Module):\n",
    "    def __init__(self, in_features, out_features):\n",
    "        super().__init__()\n",
    "        self.weight = nn.Parameter(torch.randn(out_features, in_features))\n",
    "        self.bias = nn.Parameter(torch.zeros(out_features))\n",
    "\n",
    "    def forward(self, X):\n",
    "        z = X @ self.weight.T + self.bias\n",
    "        return F.relu(z)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "d9a0d228",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 5])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.manual_seed(42)\n",
    "dense = Dense2(3,5)\n",
    "X = torch.randn(2,3)\n",
    "y_pred = dense(X)\n",
    "y_pred.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "36339563",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred_check = F.relu(X @ dense.weight.T + dense.bias)\n",
    "torch.allclose(y_pred, y_pred_check)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ffda23d4",
   "metadata": {},
   "source": [
    "Kaiming Initialization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "45e4821f",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Dense3(nn.Module):\n",
    "    def __init__(self, in_features, out_features):\n",
    "        super().__init__()\n",
    "        self.weight = nn.Parameter(torch.empty(out_features, in_features))\n",
    "        nn.init.kaiming_uniform_(self.weight, nonlinearity=\"relu\")\n",
    "        self.bias = nn.Parameter(torch.zeros(out_features))\n",
    "    \n",
    "    def forward(self, X):\n",
    "        z = X @ self.weight.T + self.bias\n",
    "        return F.relu(z)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "5b4a1446",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 5])"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.manual_seed(42)\n",
    "dense3 = Dense3(3,5)\n",
    "X = torch.randn(2,3)\n",
    "y_pred3 = dense3(X)\n",
    "y_pred3.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "99229418",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred_check = F.relu(X @ dense3.weight.T + dense3.bias)\n",
    "torch.allclose(y_pred3, y_pred_check)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1d30e53",
   "metadata": {},
   "source": [
    "15 - CoverType Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "579b94ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import fetch_covtype\n",
    "covertype = fetch_covtype(data_home=\"../datasets/\", download_if_missing=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "63b83ef3",
   "metadata": {},
   "outputs": [],
   "source": [
    "X, y = covertype.data, covertype.target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "67c38f50",
   "metadata": {},
   "outputs": [],
   "source": [
    "class_names = [\"Spruce/Fir\", \"Lodgepole Pine\", \"Ponderosa Pine\", \"Cottonwood/Willow\",\"Aspen\", \"Douglas-fir\",\"Krummholz\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "8999f597",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "np.int32(5)"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "c9b36556",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Douglas-fir'"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class_names[y[0]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "99839588",
   "metadata": {},
   "outputs": [],
   "source": [
    "# X = torch.from_numpy(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "cf65b591",
   "metadata": {},
   "outputs": [],
   "source": [
    "# The target values start from 1 \n",
    "y = y - 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "3327f310",
   "metadata": {},
   "outputs": [],
   "source": [
    "# y = y + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "7a63b6e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "cover_df = pd.DataFrame(X, columns=covertype.feature_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "7cc21f75",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Elevation</th>\n",
       "      <th>Aspect</th>\n",
       "      <th>Slope</th>\n",
       "      <th>Horizontal_Distance_To_Hydrology</th>\n",
       "      <th>Vertical_Distance_To_Hydrology</th>\n",
       "      <th>Horizontal_Distance_To_Roadways</th>\n",
       "      <th>Hillshade_9am</th>\n",
       "      <th>Hillshade_Noon</th>\n",
       "      <th>Hillshade_3pm</th>\n",
       "      <th>Horizontal_Distance_To_Fire_Points</th>\n",
       "      <th>...</th>\n",
       "      <th>Soil_Type_30</th>\n",
       "      <th>Soil_Type_31</th>\n",
       "      <th>Soil_Type_32</th>\n",
       "      <th>Soil_Type_33</th>\n",
       "      <th>Soil_Type_34</th>\n",
       "      <th>Soil_Type_35</th>\n",
       "      <th>Soil_Type_36</th>\n",
       "      <th>Soil_Type_37</th>\n",
       "      <th>Soil_Type_38</th>\n",
       "      <th>Soil_Type_39</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2596.0</td>\n",
       "      <td>51.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>258.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>510.0</td>\n",
       "      <td>221.0</td>\n",
       "      <td>232.0</td>\n",
       "      <td>148.0</td>\n",
       "      <td>6279.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2590.0</td>\n",
       "      <td>56.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>212.0</td>\n",
       "      <td>-6.0</td>\n",
       "      <td>390.0</td>\n",
       "      <td>220.0</td>\n",
       "      <td>235.0</td>\n",
       "      <td>151.0</td>\n",
       "      <td>6225.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2804.0</td>\n",
       "      <td>139.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>268.0</td>\n",
       "      <td>65.0</td>\n",
       "      <td>3180.0</td>\n",
       "      <td>234.0</td>\n",
       "      <td>238.0</td>\n",
       "      <td>135.0</td>\n",
       "      <td>6121.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2785.0</td>\n",
       "      <td>155.0</td>\n",
       "      <td>18.0</td>\n",
       "      <td>242.0</td>\n",
       "      <td>118.0</td>\n",
       "      <td>3090.0</td>\n",
       "      <td>238.0</td>\n",
       "      <td>238.0</td>\n",
       "      <td>122.0</td>\n",
       "      <td>6211.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2595.0</td>\n",
       "      <td>45.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>153.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>391.0</td>\n",
       "      <td>220.0</td>\n",
       "      <td>234.0</td>\n",
       "      <td>150.0</td>\n",
       "      <td>6172.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows  54 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Elevation  Aspect  Slope  Horizontal_Distance_To_Hydrology  \\\n",
       "0     2596.0    51.0    3.0                             258.0   \n",
       "1     2590.0    56.0    2.0                             212.0   \n",
       "2     2804.0   139.0    9.0                             268.0   \n",
       "3     2785.0   155.0   18.0                             242.0   \n",
       "4     2595.0    45.0    2.0                             153.0   \n",
       "\n",
       "   Vertical_Distance_To_Hydrology  Horizontal_Distance_To_Roadways  \\\n",
       "0                             0.0                            510.0   \n",
       "1                            -6.0                            390.0   \n",
       "2                            65.0                           3180.0   \n",
       "3                           118.0                           3090.0   \n",
       "4                            -1.0                            391.0   \n",
       "\n",
       "   Hillshade_9am  Hillshade_Noon  Hillshade_3pm  \\\n",
       "0          221.0           232.0          148.0   \n",
       "1          220.0           235.0          151.0   \n",
       "2          234.0           238.0          135.0   \n",
       "3          238.0           238.0          122.0   \n",
       "4          220.0           234.0          150.0   \n",
       "\n",
       "   Horizontal_Distance_To_Fire_Points  ...  Soil_Type_30  Soil_Type_31  \\\n",
       "0                              6279.0  ...           0.0           0.0   \n",
       "1                              6225.0  ...           0.0           0.0   \n",
       "2                              6121.0  ...           0.0           0.0   \n",
       "3                              6211.0  ...           0.0           0.0   \n",
       "4                              6172.0  ...           0.0           0.0   \n",
       "\n",
       "   Soil_Type_32  Soil_Type_33  Soil_Type_34  Soil_Type_35  Soil_Type_36  \\\n",
       "0           0.0           0.0           0.0           0.0           0.0   \n",
       "1           0.0           0.0           0.0           0.0           0.0   \n",
       "2           0.0           0.0           0.0           0.0           0.0   \n",
       "3           0.0           0.0           0.0           0.0           0.0   \n",
       "4           0.0           0.0           0.0           0.0           0.0   \n",
       "\n",
       "   Soil_Type_37  Soil_Type_38  Soil_Type_39  \n",
       "0           0.0           0.0           0.0  \n",
       "1           0.0           0.0           0.0  \n",
       "2           0.0           0.0           0.0  \n",
       "3           0.0           0.0           0.0  \n",
       "4           0.0           0.0           0.0  \n",
       "\n",
       "[5 rows x 54 columns]"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cover_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75013b20",
   "metadata": {},
   "source": [
    "We first convert meters columns to kms"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9905890b",
   "metadata": {},
   "source": [
    "cover_df[\"Elevation\"] = cover_df[\"Elevation\"] / 1000\n",
    "cover_df[\"Horizontal_Distance_To_Hydrology\"] = cover_df[\"Horizontal_Distance_To_Hydrology\"] / 1000\n",
    "cover_df[\"Vertical_Distance_To_Hydrology\"] = cover_df[\"Vertical_Distance_To_Hydrology\"] / 1000\n",
    "cover_df[\"Horizontal_Distance_To_Roadways\"] = cover_df[\"Horizontal_Distance_To_Roadways\"] / 1000\n",
    "cover_df[\"Horizontal_Distance_To_Fire_Points\"] = cover_df[\"Horizontal_Distance_To_Fire_Points\"] / 1000"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "827f6939",
   "metadata": {},
   "source": [
    "Then we scale the hillshade columns as these are 0 - 255 indexed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "2dca619b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Elevation</th>\n",
       "      <th>Aspect</th>\n",
       "      <th>Slope</th>\n",
       "      <th>Horizontal_Distance_To_Hydrology</th>\n",
       "      <th>Vertical_Distance_To_Hydrology</th>\n",
       "      <th>Horizontal_Distance_To_Roadways</th>\n",
       "      <th>Hillshade_9am</th>\n",
       "      <th>Hillshade_Noon</th>\n",
       "      <th>Hillshade_3pm</th>\n",
       "      <th>Horizontal_Distance_To_Fire_Points</th>\n",
       "      <th>...</th>\n",
       "      <th>Soil_Type_30</th>\n",
       "      <th>Soil_Type_31</th>\n",
       "      <th>Soil_Type_32</th>\n",
       "      <th>Soil_Type_33</th>\n",
       "      <th>Soil_Type_34</th>\n",
       "      <th>Soil_Type_35</th>\n",
       "      <th>Soil_Type_36</th>\n",
       "      <th>Soil_Type_37</th>\n",
       "      <th>Soil_Type_38</th>\n",
       "      <th>Soil_Type_39</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2596.0</td>\n",
       "      <td>51.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>258.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>510.0</td>\n",
       "      <td>221.0</td>\n",
       "      <td>232.0</td>\n",
       "      <td>148.0</td>\n",
       "      <td>6279.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2590.0</td>\n",
       "      <td>56.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>212.0</td>\n",
       "      <td>-6.0</td>\n",
       "      <td>390.0</td>\n",
       "      <td>220.0</td>\n",
       "      <td>235.0</td>\n",
       "      <td>151.0</td>\n",
       "      <td>6225.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2804.0</td>\n",
       "      <td>139.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>268.0</td>\n",
       "      <td>65.0</td>\n",
       "      <td>3180.0</td>\n",
       "      <td>234.0</td>\n",
       "      <td>238.0</td>\n",
       "      <td>135.0</td>\n",
       "      <td>6121.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2785.0</td>\n",
       "      <td>155.0</td>\n",
       "      <td>18.0</td>\n",
       "      <td>242.0</td>\n",
       "      <td>118.0</td>\n",
       "      <td>3090.0</td>\n",
       "      <td>238.0</td>\n",
       "      <td>238.0</td>\n",
       "      <td>122.0</td>\n",
       "      <td>6211.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2595.0</td>\n",
       "      <td>45.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>153.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>391.0</td>\n",
       "      <td>220.0</td>\n",
       "      <td>234.0</td>\n",
       "      <td>150.0</td>\n",
       "      <td>6172.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows  54 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Elevation  Aspect  Slope  Horizontal_Distance_To_Hydrology  \\\n",
       "0     2596.0    51.0    3.0                             258.0   \n",
       "1     2590.0    56.0    2.0                             212.0   \n",
       "2     2804.0   139.0    9.0                             268.0   \n",
       "3     2785.0   155.0   18.0                             242.0   \n",
       "4     2595.0    45.0    2.0                             153.0   \n",
       "\n",
       "   Vertical_Distance_To_Hydrology  Horizontal_Distance_To_Roadways  \\\n",
       "0                             0.0                            510.0   \n",
       "1                            -6.0                            390.0   \n",
       "2                            65.0                           3180.0   \n",
       "3                           118.0                           3090.0   \n",
       "4                            -1.0                            391.0   \n",
       "\n",
       "   Hillshade_9am  Hillshade_Noon  Hillshade_3pm  \\\n",
       "0          221.0           232.0          148.0   \n",
       "1          220.0           235.0          151.0   \n",
       "2          234.0           238.0          135.0   \n",
       "3          238.0           238.0          122.0   \n",
       "4          220.0           234.0          150.0   \n",
       "\n",
       "   Horizontal_Distance_To_Fire_Points  ...  Soil_Type_30  Soil_Type_31  \\\n",
       "0                              6279.0  ...           0.0           0.0   \n",
       "1                              6225.0  ...           0.0           0.0   \n",
       "2                              6121.0  ...           0.0           0.0   \n",
       "3                              6211.0  ...           0.0           0.0   \n",
       "4                              6172.0  ...           0.0           0.0   \n",
       "\n",
       "   Soil_Type_32  Soil_Type_33  Soil_Type_34  Soil_Type_35  Soil_Type_36  \\\n",
       "0           0.0           0.0           0.0           0.0           0.0   \n",
       "1           0.0           0.0           0.0           0.0           0.0   \n",
       "2           0.0           0.0           0.0           0.0           0.0   \n",
       "3           0.0           0.0           0.0           0.0           0.0   \n",
       "4           0.0           0.0           0.0           0.0           0.0   \n",
       "\n",
       "   Soil_Type_37  Soil_Type_38  Soil_Type_39  \n",
       "0           0.0           0.0           0.0  \n",
       "1           0.0           0.0           0.0  \n",
       "2           0.0           0.0           0.0  \n",
       "3           0.0           0.0           0.0  \n",
       "4           0.0           0.0           0.0  \n",
       "\n",
       "[5 rows x 54 columns]"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cover_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10429de8",
   "metadata": {},
   "source": [
    "cover_df[\"Hillshade_9am\"] = cover_df[\"Hillshade_9am\"] / 255\n",
    "cover_df[\"Hillshade_Noon\"] = cover_df[\"Hillshade_Noon\"] / 255\n",
    "cover_df[\"Hillshade_3pm\"] = cover_df[\"Hillshade_3pm\"] / 255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "3fd75893",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Elevation</th>\n",
       "      <th>Aspect</th>\n",
       "      <th>Slope</th>\n",
       "      <th>Horizontal_Distance_To_Hydrology</th>\n",
       "      <th>Vertical_Distance_To_Hydrology</th>\n",
       "      <th>Horizontal_Distance_To_Roadways</th>\n",
       "      <th>Hillshade_9am</th>\n",
       "      <th>Hillshade_Noon</th>\n",
       "      <th>Hillshade_3pm</th>\n",
       "      <th>Horizontal_Distance_To_Fire_Points</th>\n",
       "      <th>...</th>\n",
       "      <th>Soil_Type_30</th>\n",
       "      <th>Soil_Type_31</th>\n",
       "      <th>Soil_Type_32</th>\n",
       "      <th>Soil_Type_33</th>\n",
       "      <th>Soil_Type_34</th>\n",
       "      <th>Soil_Type_35</th>\n",
       "      <th>Soil_Type_36</th>\n",
       "      <th>Soil_Type_37</th>\n",
       "      <th>Soil_Type_38</th>\n",
       "      <th>Soil_Type_39</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2596.0</td>\n",
       "      <td>51.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>258.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>510.0</td>\n",
       "      <td>221.0</td>\n",
       "      <td>232.0</td>\n",
       "      <td>148.0</td>\n",
       "      <td>6279.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2590.0</td>\n",
       "      <td>56.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>212.0</td>\n",
       "      <td>-6.0</td>\n",
       "      <td>390.0</td>\n",
       "      <td>220.0</td>\n",
       "      <td>235.0</td>\n",
       "      <td>151.0</td>\n",
       "      <td>6225.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2804.0</td>\n",
       "      <td>139.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>268.0</td>\n",
       "      <td>65.0</td>\n",
       "      <td>3180.0</td>\n",
       "      <td>234.0</td>\n",
       "      <td>238.0</td>\n",
       "      <td>135.0</td>\n",
       "      <td>6121.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2785.0</td>\n",
       "      <td>155.0</td>\n",
       "      <td>18.0</td>\n",
       "      <td>242.0</td>\n",
       "      <td>118.0</td>\n",
       "      <td>3090.0</td>\n",
       "      <td>238.0</td>\n",
       "      <td>238.0</td>\n",
       "      <td>122.0</td>\n",
       "      <td>6211.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2595.0</td>\n",
       "      <td>45.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>153.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>391.0</td>\n",
       "      <td>220.0</td>\n",
       "      <td>234.0</td>\n",
       "      <td>150.0</td>\n",
       "      <td>6172.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows  54 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Elevation  Aspect  Slope  Horizontal_Distance_To_Hydrology  \\\n",
       "0     2596.0    51.0    3.0                             258.0   \n",
       "1     2590.0    56.0    2.0                             212.0   \n",
       "2     2804.0   139.0    9.0                             268.0   \n",
       "3     2785.0   155.0   18.0                             242.0   \n",
       "4     2595.0    45.0    2.0                             153.0   \n",
       "\n",
       "   Vertical_Distance_To_Hydrology  Horizontal_Distance_To_Roadways  \\\n",
       "0                             0.0                            510.0   \n",
       "1                            -6.0                            390.0   \n",
       "2                            65.0                           3180.0   \n",
       "3                           118.0                           3090.0   \n",
       "4                            -1.0                            391.0   \n",
       "\n",
       "   Hillshade_9am  Hillshade_Noon  Hillshade_3pm  \\\n",
       "0          221.0           232.0          148.0   \n",
       "1          220.0           235.0          151.0   \n",
       "2          234.0           238.0          135.0   \n",
       "3          238.0           238.0          122.0   \n",
       "4          220.0           234.0          150.0   \n",
       "\n",
       "   Horizontal_Distance_To_Fire_Points  ...  Soil_Type_30  Soil_Type_31  \\\n",
       "0                              6279.0  ...           0.0           0.0   \n",
       "1                              6225.0  ...           0.0           0.0   \n",
       "2                              6121.0  ...           0.0           0.0   \n",
       "3                              6211.0  ...           0.0           0.0   \n",
       "4                              6172.0  ...           0.0           0.0   \n",
       "\n",
       "   Soil_Type_32  Soil_Type_33  Soil_Type_34  Soil_Type_35  Soil_Type_36  \\\n",
       "0           0.0           0.0           0.0           0.0           0.0   \n",
       "1           0.0           0.0           0.0           0.0           0.0   \n",
       "2           0.0           0.0           0.0           0.0           0.0   \n",
       "3           0.0           0.0           0.0           0.0           0.0   \n",
       "4           0.0           0.0           0.0           0.0           0.0   \n",
       "\n",
       "   Soil_Type_37  Soil_Type_38  Soil_Type_39  \n",
       "0           0.0           0.0           0.0  \n",
       "1           0.0           0.0           0.0  \n",
       "2           0.0           0.0           0.0  \n",
       "3           0.0           0.0           0.0  \n",
       "4           0.0           0.0           0.0  \n",
       "\n",
       "[5 rows x 54 columns]"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cover_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "81b2f9d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = cover_df.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "82df92d3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((581012, 54), (581012,))"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape, y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "2c944837",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(numpy.ndarray, numpy.ndarray)"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(X), type(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "80bf8754",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(581012, 54)"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mean = X.mean(axis = 0)\n",
    "std = X.std(axis = 0)\n",
    "X = (X - mean) / std\n",
    "\n",
    "X.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76d9cf51",
   "metadata": {},
   "source": [
    "Shuffling and choosing the first 100,000 instances for training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "af735a97",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_tensor = torch.from_numpy(X).float()\n",
    "y_tensor = torch.from_numpy(y).to(torch.int64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "1fb00a49",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([581012, 54]), torch.Size([581012]))"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_tensor.shape, y_tensor.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "07f9f800",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import TensorDataset\n",
    "from torch.utils.data import random_split\n",
    "torch.manual_seed(42)\n",
    "\n",
    "covtype_dataset = TensorDataset(X_tensor, y_tensor)\n",
    "\n",
    "train_size = len(covtype_dataset) * 80 // 100\n",
    "valid_size = len(covtype_dataset) * 10 // 100\n",
    "test_size = len(covtype_dataset) - train_size - valid_size\n",
    "\n",
    "train_data, valid_data, test_data = random_split(covtype_dataset, [train_size, valid_size, test_size])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4750d57e",
   "metadata": {},
   "source": [
    "The below X and y will be our final dataset where which will extract the train, validation and test set."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7d6e7b3",
   "metadata": {},
   "source": [
    "But before that, let us normalize our dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef9d4f03",
   "metadata": {},
   "source": [
    "Creating dataloaders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "bf114977",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = DataLoader(train_data, batch_size=256)\n",
    "valid_loader = DataLoader(valid_data, batch_size=256)\n",
    "test_loader = DataLoader(test_data, batch_size=256)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "432d9dce",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'cuda'"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02458de5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "61d2b29f",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CovTypeClassifier(nn.Module):\n",
    "    def __init__(self, n_inputs, num_hidden_neurons, n_classes):\n",
    "        super().__init__()\n",
    "        layers = [\n",
    "            Dense3(n_in, n_out)\n",
    "            for n_in, n_out in zip([n_inputs] + num_hidden_neurons, num_hidden_neurons)\n",
    "        ] + [nn.Linear(num_hidden_neurons[-1], n_classes)]\n",
    "        self.layers = nn.ModuleList(layers)\n",
    "\n",
    "    def forward(self, X):\n",
    "        for layer in self.layers:\n",
    "            X = layer(X)\n",
    "        return X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "70c2d70c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1/40, Train Loss: 0.7672 Train metric: 0.6916 Valid Metrics: 0.7338 Total Loss: 1393.2309 Loss.item(): 0.632655680179596\n",
      "Epoch: 2/40, Train Loss: 0.6205 Train metric: 0.7426 Valid Metrics: 0.7481 Total Loss: 1126.9004 Loss.item(): 0.5522188544273376\n",
      "Epoch: 3/40, Train Loss: 0.5843 Train metric: 0.7546 Valid Metrics: 0.7586 Total Loss: 1061.0636 Loss.item(): 0.5153619050979614\n",
      "Epoch: 4/40, Train Loss: 0.5593 Train metric: 0.7641 Valid Metrics: 0.7671 Total Loss: 1015.6307 Loss.item(): 0.49745941162109375\n",
      "Epoch: 5/40, Train Loss: 0.5391 Train metric: 0.7714 Valid Metrics: 0.7744 Total Loss: 979.0868 Loss.item(): 0.4835699796676636\n",
      "Epoch: 6/40, Train Loss: 0.5219 Train metric: 0.7784 Valid Metrics: 0.7821 Total Loss: 947.8314 Loss.item(): 0.4691464602947235\n",
      "Epoch: 7/40, Train Loss: 0.5074 Train metric: 0.7851 Valid Metrics: 0.7879 Total Loss: 921.4667 Loss.item(): 0.45597681403160095\n",
      "Epoch: 8/40, Train Loss: 0.4949 Train metric: 0.7914 Valid Metrics: 0.7944 Total Loss: 898.7273 Loss.item(): 0.4459863305091858\n",
      "Epoch: 9/40, Train Loss: 0.4837 Train metric: 0.7972 Valid Metrics: 0.8000 Total Loss: 878.4261 Loss.item(): 0.43627700209617615\n",
      "Epoch: 10/40, Train Loss: 0.4736 Train metric: 0.8025 Valid Metrics: 0.8055 Total Loss: 860.0002 Loss.item(): 0.42818012833595276\n",
      "Epoch: 11/40, Train Loss: 0.4641 Train metric: 0.8072 Valid Metrics: 0.8106 Total Loss: 842.8365 Loss.item(): 0.4215993583202362\n",
      "Epoch: 12/40, Train Loss: 0.4554 Train metric: 0.8113 Valid Metrics: 0.8149 Total Loss: 827.0041 Loss.item(): 0.4162915050983429\n",
      "Epoch: 13/40, Train Loss: 0.4474 Train metric: 0.8150 Valid Metrics: 0.8190 Total Loss: 812.4959 Loss.item(): 0.41113561391830444\n",
      "Epoch: 14/40, Train Loss: 0.4399 Train metric: 0.8185 Valid Metrics: 0.8217 Total Loss: 798.8264 Loss.item(): 0.40814724564552307\n",
      "Epoch: 15/40, Train Loss: 0.4327 Train metric: 0.8216 Valid Metrics: 0.8242 Total Loss: 785.8602 Loss.item(): 0.4058862328529358\n",
      "Epoch: 16/40, Train Loss: 0.4263 Train metric: 0.8244 Valid Metrics: 0.8266 Total Loss: 774.0956 Loss.item(): 0.4041316509246826\n",
      "Epoch: 17/40, Train Loss: 0.4199 Train metric: 0.8273 Valid Metrics: 0.8287 Total Loss: 762.4767 Loss.item(): 0.4027419090270996\n",
      "Epoch: 18/40, Train Loss: 0.4140 Train metric: 0.8302 Valid Metrics: 0.8313 Total Loss: 751.7924 Loss.item(): 0.399864137172699\n",
      "Epoch: 19/40, Train Loss: 0.4086 Train metric: 0.8325 Valid Metrics: 0.8334 Total Loss: 741.9472 Loss.item(): 0.3960399627685547\n",
      "Epoch: 20/40, Train Loss: 0.4033 Train metric: 0.8348 Valid Metrics: 0.8361 Total Loss: 732.3758 Loss.item(): 0.38792479038238525\n",
      "Epoch: 21/40, Train Loss: 0.3982 Train metric: 0.8372 Valid Metrics: 0.8383 Total Loss: 723.0607 Loss.item(): 0.38497424125671387\n",
      "Epoch: 22/40, Train Loss: 0.3931 Train metric: 0.8395 Valid Metrics: 0.8406 Total Loss: 713.8333 Loss.item(): 0.37843242287635803\n",
      "Epoch: 23/40, Train Loss: 0.3882 Train metric: 0.8416 Valid Metrics: 0.8426 Total Loss: 705.0502 Loss.item(): 0.37108078598976135\n",
      "Epoch: 24/40, Train Loss: 0.3836 Train metric: 0.8436 Valid Metrics: 0.8437 Total Loss: 696.5410 Loss.item(): 0.3629850447177887\n",
      "Epoch: 25/40, Train Loss: 0.3795 Train metric: 0.8454 Valid Metrics: 0.8457 Total Loss: 689.2250 Loss.item(): 0.3584342896938324\n",
      "Epoch: 26/40, Train Loss: 0.3755 Train metric: 0.8474 Valid Metrics: 0.8472 Total Loss: 681.8172 Loss.item(): 0.3529987037181854\n",
      "Epoch: 27/40, Train Loss: 0.3710 Train metric: 0.8493 Valid Metrics: 0.8484 Total Loss: 673.6815 Loss.item(): 0.3467956483364105\n",
      "Epoch: 28/40, Train Loss: 0.3675 Train metric: 0.8508 Valid Metrics: 0.8499 Total Loss: 667.3358 Loss.item(): 0.3423245847225189\n",
      "Epoch: 29/40, Train Loss: 0.3636 Train metric: 0.8525 Valid Metrics: 0.8511 Total Loss: 660.3368 Loss.item(): 0.3372359275817871\n",
      "Epoch: 30/40, Train Loss: 0.3603 Train metric: 0.8541 Valid Metrics: 0.8523 Total Loss: 654.3594 Loss.item(): 0.3346177637577057\n",
      "Epoch: 31/40, Train Loss: 0.3568 Train metric: 0.8559 Valid Metrics: 0.8534 Total Loss: 648.0276 Loss.item(): 0.3311939835548401\n",
      "Epoch: 32/40, Train Loss: 0.3534 Train metric: 0.8573 Valid Metrics: 0.8549 Total Loss: 641.7870 Loss.item(): 0.3278641104698181\n",
      "Epoch: 33/40, Train Loss: 0.3501 Train metric: 0.8588 Valid Metrics: 0.8563 Total Loss: 635.7070 Loss.item(): 0.3243821859359741\n",
      "Epoch: 34/40, Train Loss: 0.3465 Train metric: 0.8603 Valid Metrics: 0.8575 Total Loss: 629.2982 Loss.item(): 0.3212280869483948\n",
      "Epoch: 35/40, Train Loss: 0.3436 Train metric: 0.8615 Valid Metrics: 0.8594 Total Loss: 624.0058 Loss.item(): 0.31957361102104187\n",
      "Epoch: 36/40, Train Loss: 0.3405 Train metric: 0.8628 Valid Metrics: 0.8602 Total Loss: 618.4029 Loss.item(): 0.31869417428970337\n",
      "Epoch: 37/40, Train Loss: 0.3377 Train metric: 0.8640 Valid Metrics: 0.8617 Total Loss: 613.1727 Loss.item(): 0.3180757761001587\n",
      "Epoch: 38/40, Train Loss: 0.3346 Train metric: 0.8653 Valid Metrics: 0.8623 Total Loss: 607.6616 Loss.item(): 0.3128081262111664\n",
      "Epoch: 39/40, Train Loss: 0.3318 Train metric: 0.8664 Valid Metrics: 0.8640 Total Loss: 602.5741 Loss.item(): 0.31378456950187683\n",
      "Epoch: 40/40, Train Loss: 0.3294 Train metric: 0.8676 Valid Metrics: 0.8649 Total Loss: 598.0999 Loss.item(): 0.31104204058647156\n"
     ]
    }
   ],
   "source": [
    "model = CovTypeClassifier(n_inputs=54, num_hidden_neurons=[200,100,50], n_classes=7).to(device)\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr = 0.01)\n",
    "loss = nn.CrossEntropyLoss().to(device)\n",
    "accuracy = torchmetrics.Accuracy(task=\"multiclass\", num_classes=7).to(device)\n",
    "\n",
    "history = train2(model, optimizer, loss, accuracy, train_loader, valid_loader, 40)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "d4bb80f4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.8643, device='cuda:0')"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_metrics = evaluate_tm(model, test_loader, accuracy)\n",
    "test_metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3b2c1ca",
   "metadata": {},
   "source": [
    "Tuning hyperparameters with optuna"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "b15c4ddb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def objective(trial):\n",
    "    learning_rate = trial.suggest_float(\"learning_rate\", 1e-5, 1.0, log = True)\n",
    "    n_layers = trial.suggest_int(\"n_layers\", 1, 5)\n",
    "    n_hidden_neurons = trial.suggest_int(\"n_hidden_neurons\",30, 200)\n",
    "    covtype_model = CovTypeClassifier(n_inputs=54, num_hidden_neurons=[n_hidden_neurons] * n_layers, n_classes = 7).to(device)\n",
    "    optimizer = torch.optim.SGD(covtype_model.parameters(), lr = learning_rate)\n",
    "    xentropy = nn.CrossEntropyLoss()\n",
    "    accuracy = torchmetrics.Accuracy(task=\"multiclass\", num_classes=7).to(device)\n",
    "\n",
    "    best_validation_accuracy = 0\n",
    "    for epoch in range(n_epochs):\n",
    "        history = train2(covtype_model, optimizer, xentropy, accuracy, train_loader, valid_loader, n_epochs=1)\n",
    "        validation_accuracy = max(history[\"valid_metrics\"])\n",
    "\n",
    "        if validation_accuracy > best_validation_accuracy:\n",
    "            best_validation_accuracy = validation_accuracy\n",
    "        trial.report(validation_accuracy, step = epoch)\n",
    "\n",
    "        if trial.should_prune():\n",
    "            raise optuna.TrialPruned()\n",
    "    return best_validation_accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "id": "d615bb77",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_9915/1845997949.py:2: FutureWarning: __init__() got {'consider_prior'} as positional arguments but they were expected to be given as keyword arguments.\n",
      "Positional arguments ['self', 'consider_prior', 'prior_weight', 'consider_magic_clip', 'consider_endpoints', 'n_startup_trials', 'n_ei_candidates', 'gamma', 'weights', 'seed'] in __init__() have been deprecated since v4.4.0. They will be replaced with the corresponding keyword arguments in v6.0.0, so please use the keyword specification instead. See https://github.com/optuna/optuna/releases/tag/v4.4.0 for details.\n",
      "  sampler = optuna.samplers.TPESampler(42)\n",
      "[I 2026-01-09 18:38:43,320] A new study created in memory with name: no-name-580a3335-9c8d-42c1-bb0c-bdb1e331c592\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1/1, Train Loss: 1.6214 Train metric: 0.4443 Valid Metrics: 0.5088 Total Loss: 2944.5202 Loss.item(): 1.5545099973678589\n",
      "Epoch: 1/1, Train Loss: 1.3711 Train metric: 0.5239 Valid Metrics: 0.5427 Total Loss: 2489.9606 Loss.item(): 1.4520944356918335\n",
      "Epoch: 1/1, Train Loss: 1.2768 Train metric: 0.5510 Valid Metrics: 0.5674 Total Loss: 2318.5948 Loss.item(): 1.3720388412475586\n",
      "Epoch: 1/1, Train Loss: 1.2049 Train metric: 0.5773 Valid Metrics: 0.5907 Total Loss: 2188.0976 Loss.item(): 1.3077129125595093\n",
      "Epoch: 1/1, Train Loss: 1.1456 Train metric: 0.5954 Valid Metrics: 0.6019 Total Loss: 2080.3376 Loss.item(): 1.2537262439727783\n",
      "Epoch: 1/1, Train Loss: 1.0948 Train metric: 0.6038 Valid Metrics: 0.6081 Total Loss: 1988.1478 Loss.item(): 1.2069717645645142\n",
      "Epoch: 1/1, Train Loss: 1.0505 Train metric: 0.6098 Valid Metrics: 0.6143 Total Loss: 1907.7526 Loss.item(): 1.1657072305679321\n",
      "Epoch: 1/1, Train Loss: 1.0115 Train metric: 0.6157 Valid Metrics: 0.6212 Total Loss: 1836.9346 Loss.item(): 1.1288220882415771\n",
      "Epoch: 1/1, Train Loss: 0.9771 Train metric: 0.6223 Valid Metrics: 0.6278 Total Loss: 1774.3811 Loss.item(): 1.0955950021743774\n",
      "Epoch: 1/1, Train Loss: 0.9468 Train metric: 0.6301 Valid Metrics: 0.6359 Total Loss: 1719.4542 Loss.item(): 1.0659983158111572\n",
      "Epoch: 1/1, Train Loss: 0.9205 Train metric: 0.6380 Valid Metrics: 0.6438 Total Loss: 1671.6443 Loss.item(): 1.039441704750061\n",
      "Epoch: 1/1, Train Loss: 0.8976 Train metric: 0.6449 Valid Metrics: 0.6508 Total Loss: 1630.0797 Loss.item(): 1.0152219533920288\n",
      "Epoch: 1/1, Train Loss: 0.8777 Train metric: 0.6508 Valid Metrics: 0.6565 Total Loss: 1593.8277 Loss.item(): 0.9930830001831055\n",
      "Epoch: 1/1, Train Loss: 0.8602 Train metric: 0.6566 Valid Metrics: 0.6608 Total Loss: 1562.0898 Loss.item(): 0.9728208184242249\n",
      "Epoch: 1/1, Train Loss: 0.8448 Train metric: 0.6617 Valid Metrics: 0.6645 Total Loss: 1534.2146 Loss.item(): 0.9545195698738098\n",
      "Epoch: 1/1, Train Loss: 0.8313 Train metric: 0.6661 Valid Metrics: 0.6682 Total Loss: 1509.6409 Loss.item(): 0.9379204511642456\n",
      "Epoch: 1/1, Train Loss: 0.8193 Train metric: 0.6700 Valid Metrics: 0.6713 Total Loss: 1487.9209 Loss.item(): 0.9229843020439148\n",
      "Epoch: 1/1, Train Loss: 0.8087 Train metric: 0.6737 Valid Metrics: 0.6750 Total Loss: 1468.6386 Loss.item(): 0.9095642566680908\n",
      "Epoch: 1/1, Train Loss: 0.7992 Train metric: 0.6770 Valid Metrics: 0.6774 Total Loss: 1451.4143 Loss.item(): 0.8973408341407776\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2026-01-09 18:40:02,618] Trial 0 finished with value: 0.6801948547363281 and parameters: {'learning_rate': 0.00011228684920439126, 'n_layers': 3, 'n_hidden_neurons': 149}. Best is trial 0 with value: 0.6801948547363281.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1/1, Train Loss: 0.7907 Train metric: 0.6799 Valid Metrics: 0.6802 Total Loss: 1435.9212 Loss.item(): 0.8862407803535461\n",
      "Epoch: 1/1, Train Loss: 0.6190 Train metric: 0.7362 Valid Metrics: 0.7753 Total Loss: 1124.0395 Loss.item(): 0.45074692368507385\n",
      "Epoch: 1/1, Train Loss: 0.4957 Train metric: 0.7902 Valid Metrics: 0.8095 Total Loss: 900.1868 Loss.item(): 0.40645739436149597\n",
      "Epoch: 1/1, Train Loss: 0.4430 Train metric: 0.8149 Valid Metrics: 0.8245 Total Loss: 804.4723 Loss.item(): 0.37614771723747253\n",
      "Epoch: 1/1, Train Loss: 0.4067 Train metric: 0.8311 Valid Metrics: 0.8360 Total Loss: 738.5960 Loss.item(): 0.3484655022621155\n",
      "Epoch: 1/1, Train Loss: 0.3799 Train metric: 0.8434 Valid Metrics: 0.8475 Total Loss: 689.9675 Loss.item(): 0.3328278362751007\n",
      "Epoch: 1/1, Train Loss: 0.3593 Train metric: 0.8523 Valid Metrics: 0.8533 Total Loss: 652.3983 Loss.item(): 0.3219091296195984\n",
      "Epoch: 1/1, Train Loss: 0.3422 Train metric: 0.8599 Valid Metrics: 0.8560 Total Loss: 621.5023 Loss.item(): 0.3143521547317505\n",
      "Epoch: 1/1, Train Loss: 0.3286 Train metric: 0.8654 Valid Metrics: 0.8600 Total Loss: 596.8052 Loss.item(): 0.27538666129112244\n",
      "Epoch: 1/1, Train Loss: 0.3171 Train metric: 0.8705 Valid Metrics: 0.8644 Total Loss: 575.8275 Loss.item(): 0.26108551025390625\n",
      "Epoch: 1/1, Train Loss: 0.3068 Train metric: 0.8752 Valid Metrics: 0.8699 Total Loss: 557.0935 Loss.item(): 0.2447129189968109\n",
      "Epoch: 1/1, Train Loss: 0.2975 Train metric: 0.8792 Valid Metrics: 0.8710 Total Loss: 540.2334 Loss.item(): 0.23915985226631165\n",
      "Epoch: 1/1, Train Loss: 0.2893 Train metric: 0.8827 Valid Metrics: 0.8736 Total Loss: 525.3260 Loss.item(): 0.2598840296268463\n",
      "Epoch: 1/1, Train Loss: 0.2822 Train metric: 0.8857 Valid Metrics: 0.8740 Total Loss: 512.4074 Loss.item(): 0.21529032289981842\n",
      "Epoch: 1/1, Train Loss: 0.2760 Train metric: 0.8890 Valid Metrics: 0.8784 Total Loss: 501.1742 Loss.item(): 0.19571150839328766\n",
      "Epoch: 1/1, Train Loss: 0.2701 Train metric: 0.8911 Valid Metrics: 0.8838 Total Loss: 490.5910 Loss.item(): 0.2037072330713272\n",
      "Epoch: 1/1, Train Loss: 0.2645 Train metric: 0.8934 Valid Metrics: 0.8857 Total Loss: 480.4058 Loss.item(): 0.20788227021694183\n",
      "Epoch: 1/1, Train Loss: 0.2595 Train metric: 0.8955 Valid Metrics: 0.8842 Total Loss: 471.3108 Loss.item(): 0.21545585989952087\n",
      "Epoch: 1/1, Train Loss: 0.2556 Train metric: 0.8969 Valid Metrics: 0.8887 Total Loss: 464.1027 Loss.item(): 0.20161248743534088\n",
      "Epoch: 1/1, Train Loss: 0.2512 Train metric: 0.8987 Valid Metrics: 0.8903 Total Loss: 456.2310 Loss.item(): 0.20281267166137695\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2026-01-09 18:41:29,413] Trial 1 finished with value: 0.8903117179870605 and parameters: {'learning_rate': 0.081660788983419, 'n_layers': 5, 'n_hidden_neurons': 59}. Best is trial 1 with value: 0.8903117179870605.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1/1, Train Loss: 0.2477 Train metric: 0.9005 Valid Metrics: 0.8901 Total Loss: 449.7513 Loss.item(): 0.2164967805147171\n",
      "Epoch: 1/1, Train Loss: 1.8934 Train metric: 0.2837 Valid Metrics: 0.4918 Total Loss: 3438.3242 Loss.item(): 1.6668553352355957\n",
      "Epoch: 1/1, Train Loss: 1.5262 Train metric: 0.4900 Valid Metrics: 0.4995 Total Loss: 2771.6401 Loss.item(): 1.545752763748169\n",
      "Epoch: 1/1, Train Loss: 1.4191 Train metric: 0.4954 Valid Metrics: 0.5074 Total Loss: 2577.0818 Loss.item(): 1.5043952465057373\n",
      "Epoch: 1/1, Train Loss: 1.3685 Train metric: 0.5048 Valid Metrics: 0.5180 Total Loss: 2485.1869 Loss.item(): 1.478681206703186\n",
      "Epoch: 1/1, Train Loss: 1.3348 Train metric: 0.5166 Valid Metrics: 0.5298 Total Loss: 2424.0310 Loss.item(): 1.4563469886779785\n",
      "Epoch: 1/1, Train Loss: 1.3076 Train metric: 0.5276 Valid Metrics: 0.5398 Total Loss: 2374.6740 Loss.item(): 1.4351063966751099\n",
      "Epoch: 1/1, Train Loss: 1.2837 Train metric: 0.5378 Valid Metrics: 0.5513 Total Loss: 2331.1968 Loss.item(): 1.414754867553711\n",
      "Epoch: 1/1, Train Loss: 1.2617 Train metric: 0.5480 Valid Metrics: 0.5610 Total Loss: 2291.2265 Loss.item(): 1.3950823545455933\n",
      "Epoch: 1/1, Train Loss: 1.2410 Train metric: 0.5565 Valid Metrics: 0.5675 Total Loss: 2253.5887 Loss.item(): 1.3760849237442017\n",
      "Epoch: 1/1, Train Loss: 1.2212 Train metric: 0.5626 Valid Metrics: 0.5722 Total Loss: 2217.6123 Loss.item(): 1.3575944900512695\n",
      "Epoch: 1/1, Train Loss: 1.2020 Train metric: 0.5668 Valid Metrics: 0.5748 Total Loss: 2182.8959 Loss.item(): 1.3395240306854248\n",
      "Epoch: 1/1, Train Loss: 1.1835 Train metric: 0.5702 Valid Metrics: 0.5782 Total Loss: 2149.2038 Loss.item(): 1.32194983959198\n",
      "Epoch: 1/1, Train Loss: 1.1654 Train metric: 0.5732 Valid Metrics: 0.5803 Total Loss: 2116.4205 Loss.item(): 1.30487859249115\n",
      "Epoch: 1/1, Train Loss: 1.1479 Train metric: 0.5764 Valid Metrics: 0.5835 Total Loss: 2084.5150 Loss.item(): 1.288206696510315\n",
      "Epoch: 1/1, Train Loss: 1.1308 Train metric: 0.5806 Valid Metrics: 0.5885 Total Loss: 2053.5137 Loss.item(): 1.2720037698745728\n",
      "Epoch: 1/1, Train Loss: 1.1142 Train metric: 0.5864 Valid Metrics: 0.5945 Total Loss: 2023.4731 Loss.item(): 1.2563366889953613\n",
      "Epoch: 1/1, Train Loss: 1.0982 Train metric: 0.5926 Valid Metrics: 0.6011 Total Loss: 1994.4198 Loss.item(): 1.2411158084869385\n",
      "Epoch: 1/1, Train Loss: 1.0828 Train metric: 0.5998 Valid Metrics: 0.6086 Total Loss: 1966.3864 Loss.item(): 1.2264324426651\n",
      "Epoch: 1/1, Train Loss: 1.0680 Train metric: 0.6073 Valid Metrics: 0.6150 Total Loss: 1939.4122 Loss.item(): 1.21232271194458\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2026-01-09 18:42:53,595] Trial 2 finished with value: 0.6207466125488281 and parameters: {'learning_rate': 5.410274966873259e-05, 'n_layers': 4, 'n_hidden_neurons': 74}. Best is trial 1 with value: 0.8903117179870605.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1/1, Train Loss: 1.0537 Train metric: 0.6140 Valid Metrics: 0.6207 Total Loss: 1913.5367 Loss.item(): 1.1988117694854736\n",
      "Epoch: 1/1, Train Loss: 1.5733 Train metric: 0.4362 Valid Metrics: 0.4816 Total Loss: 2857.0565 Loss.item(): 1.4841258525848389\n",
      "Epoch: 1/1, Train Loss: 1.3312 Train metric: 0.5051 Valid Metrics: 0.5388 Total Loss: 2417.4621 Loss.item(): 1.3662372827529907\n",
      "Epoch: 1/1, Train Loss: 1.2216 Train metric: 0.5593 Valid Metrics: 0.5856 Total Loss: 2218.4886 Loss.item(): 1.2788829803466797\n",
      "Epoch: 1/1, Train Loss: 1.1425 Train metric: 0.5919 Valid Metrics: 0.6038 Total Loss: 2074.7656 Loss.item(): 1.2113802433013916\n",
      "Epoch: 1/1, Train Loss: 1.0809 Train metric: 0.6070 Valid Metrics: 0.6170 Total Loss: 1962.9282 Loss.item(): 1.1573632955551147\n",
      "Epoch: 1/1, Train Loss: 1.0317 Train metric: 0.6207 Valid Metrics: 0.6286 Total Loss: 1873.4900 Loss.item(): 1.1134366989135742\n",
      "Epoch: 1/1, Train Loss: 0.9918 Train metric: 0.6321 Valid Metrics: 0.6387 Total Loss: 1801.1289 Loss.item(): 1.0771669149398804\n",
      "Epoch: 1/1, Train Loss: 0.9592 Train metric: 0.6409 Valid Metrics: 0.6473 Total Loss: 1741.9532 Loss.item(): 1.046816110610962\n",
      "Epoch: 1/1, Train Loss: 0.9322 Train metric: 0.6476 Valid Metrics: 0.6527 Total Loss: 1692.8040 Loss.item(): 1.0206410884857178\n",
      "Epoch: 1/1, Train Loss: 0.9092 Train metric: 0.6536 Valid Metrics: 0.6570 Total Loss: 1651.1698 Loss.item(): 0.9978520274162292\n",
      "Epoch: 1/1, Train Loss: 0.8894 Train metric: 0.6580 Valid Metrics: 0.6608 Total Loss: 1615.2260 Loss.item(): 0.9775192141532898\n",
      "Epoch: 1/1, Train Loss: 0.8721 Train metric: 0.6618 Valid Metrics: 0.6636 Total Loss: 1583.7279 Loss.item(): 0.958666205406189\n",
      "Epoch: 1/1, Train Loss: 0.8567 Train metric: 0.6653 Valid Metrics: 0.6672 Total Loss: 1555.7934 Loss.item(): 0.9410896897315979\n",
      "Epoch: 1/1, Train Loss: 0.8429 Train metric: 0.6686 Valid Metrics: 0.6706 Total Loss: 1530.7864 Loss.item(): 0.924665629863739\n",
      "Epoch: 1/1, Train Loss: 0.8305 Train metric: 0.6717 Valid Metrics: 0.6735 Total Loss: 1508.2287 Loss.item(): 0.9092309474945068\n",
      "Epoch: 1/1, Train Loss: 0.8193 Train metric: 0.6741 Valid Metrics: 0.6759 Total Loss: 1487.7651 Loss.item(): 0.8948251605033875\n",
      "Epoch: 1/1, Train Loss: 0.8090 Train metric: 0.6766 Valid Metrics: 0.6784 Total Loss: 1469.1232 Loss.item(): 0.8814674019813538\n",
      "Epoch: 1/1, Train Loss: 0.7996 Train metric: 0.6790 Valid Metrics: 0.6808 Total Loss: 1452.0966 Loss.item(): 0.8691093921661377\n",
      "Epoch: 1/1, Train Loss: 0.7910 Train metric: 0.6813 Valid Metrics: 0.6828 Total Loss: 1436.5333 Loss.item(): 0.8578266501426697\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2026-01-09 18:44:10,743] Trial 3 finished with value: 0.6846697926521301 and parameters: {'learning_rate': 0.00025904067027019215, 'n_layers': 2, 'n_hidden_neurons': 57}. Best is trial 1 with value: 0.8903117179870605.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1/1, Train Loss: 0.7832 Train metric: 0.6834 Valid Metrics: 0.6847 Total Loss: 1422.3329 Loss.item(): 0.8477583527565002\n",
      "Epoch: 1/1, Train Loss: 1.8360 Train metric: 0.3420 Valid Metrics: 0.4026 Total Loss: 3334.2102 Loss.item(): 1.8164129257202148\n",
      "Epoch: 1/1, Train Loss: 1.6481 Train metric: 0.4438 Valid Metrics: 0.4693 Total Loss: 2993.0082 Loss.item(): 1.6952406167984009\n",
      "Epoch: 1/1, Train Loss: 1.5530 Train metric: 0.4803 Valid Metrics: 0.4900 Total Loss: 2820.1792 Loss.item(): 1.6360918283462524\n",
      "Epoch: 1/1, Train Loss: 1.4973 Train metric: 0.4921 Valid Metrics: 0.4979 Total Loss: 2719.0353 Loss.item(): 1.6001348495483398\n",
      "Epoch: 1/1, Train Loss: 1.4585 Train metric: 0.4974 Valid Metrics: 0.5011 Total Loss: 2648.5876 Loss.item(): 1.5734277963638306\n",
      "Epoch: 1/1, Train Loss: 1.4283 Train metric: 0.5006 Valid Metrics: 0.5036 Total Loss: 2593.7436 Loss.item(): 1.5511537790298462\n",
      "Epoch: 1/1, Train Loss: 1.4031 Train metric: 0.5029 Valid Metrics: 0.5065 Total Loss: 2548.0192 Loss.item(): 1.5314384698867798\n",
      "Epoch: 1/1, Train Loss: 1.3811 Train metric: 0.5049 Valid Metrics: 0.5088 Total Loss: 2508.1275 Loss.item(): 1.5133699178695679\n",
      "Epoch: 1/1, Train Loss: 1.3614 Train metric: 0.5069 Valid Metrics: 0.5104 Total Loss: 2472.2284 Loss.item(): 1.4962431192398071\n",
      "Epoch: 1/1, Train Loss: 1.3432 Train metric: 0.5087 Valid Metrics: 0.5117 Total Loss: 2439.2851 Loss.item(): 1.4799349308013916\n",
      "Epoch: 1/1, Train Loss: 1.3264 Train metric: 0.5103 Valid Metrics: 0.5136 Total Loss: 2408.6664 Loss.item(): 1.4645756483078003\n",
      "Epoch: 1/1, Train Loss: 1.3105 Train metric: 0.5119 Valid Metrics: 0.5152 Total Loss: 2379.9397 Loss.item(): 1.4497928619384766\n",
      "Epoch: 1/1, Train Loss: 1.2956 Train metric: 0.5134 Valid Metrics: 0.5170 Total Loss: 2352.8544 Loss.item(): 1.4354276657104492\n",
      "Epoch: 1/1, Train Loss: 1.2815 Train metric: 0.5152 Valid Metrics: 0.5182 Total Loss: 2327.2149 Loss.item(): 1.4218956232070923\n",
      "Epoch: 1/1, Train Loss: 1.2681 Train metric: 0.5169 Valid Metrics: 0.5198 Total Loss: 2302.8406 Loss.item(): 1.4090642929077148\n",
      "Epoch: 1/1, Train Loss: 1.2553 Train metric: 0.5184 Valid Metrics: 0.5211 Total Loss: 2279.5993 Loss.item(): 1.396955132484436\n",
      "Epoch: 1/1, Train Loss: 1.2430 Train metric: 0.5199 Valid Metrics: 0.5227 Total Loss: 2257.3674 Loss.item(): 1.38522469997406\n",
      "Epoch: 1/1, Train Loss: 1.2313 Train metric: 0.5214 Valid Metrics: 0.5242 Total Loss: 2236.0163 Loss.item(): 1.373917579650879\n",
      "Epoch: 1/1, Train Loss: 1.2200 Train metric: 0.5230 Valid Metrics: 0.5257 Total Loss: 2215.4319 Loss.item(): 1.3629523515701294\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2026-01-09 18:45:31,700] Trial 4 finished with value: 0.5274608135223389 and parameters: {'learning_rate': 4.039315626348698e-05, 'n_layers': 4, 'n_hidden_neurons': 41}. Best is trial 1 with value: 0.8903117179870605.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1/1, Train Loss: 1.2090 Train metric: 0.5247 Valid Metrics: 0.5275 Total Loss: 2195.5211 Loss.item(): 1.3523309230804443\n",
      "Epoch: 1/1, Train Loss: 1.2736 Train metric: 0.5549 Valid Metrics: 0.6270 Total Loss: 2312.9048 Loss.item(): 1.1698559522628784\n",
      "Epoch: 1/1, Train Loss: 1.0034 Train metric: 0.6339 Valid Metrics: 0.6452 Total Loss: 1822.0914 Loss.item(): 1.0219173431396484\n",
      "Epoch: 1/1, Train Loss: 0.9101 Train metric: 0.6551 Valid Metrics: 0.6672 Total Loss: 1652.7050 Loss.item(): 0.9437324404716492\n",
      "Epoch: 1/1, Train Loss: 0.8551 Train metric: 0.6717 Valid Metrics: 0.6777 Total Loss: 1552.8969 Loss.item(): 0.8934961557388306\n",
      "Epoch: 1/1, Train Loss: 0.8175 Train metric: 0.6806 Valid Metrics: 0.6845 Total Loss: 1484.5161 Loss.item(): 0.8567821979522705\n",
      "Epoch: 1/1, Train Loss: 0.7900 Train metric: 0.6882 Valid Metrics: 0.6939 Total Loss: 1434.7124 Loss.item(): 0.8300954699516296\n",
      "Epoch: 1/1, Train Loss: 0.7700 Train metric: 0.6955 Valid Metrics: 0.7013 Total Loss: 1398.3142 Loss.item(): 0.8106572031974792\n",
      "Epoch: 1/1, Train Loss: 0.7549 Train metric: 0.7014 Valid Metrics: 0.7062 Total Loss: 1370.8257 Loss.item(): 0.7954599261283875\n",
      "Epoch: 1/1, Train Loss: 0.7429 Train metric: 0.7062 Valid Metrics: 0.7095 Total Loss: 1349.1815 Loss.item(): 0.7830638885498047\n",
      "Epoch: 1/1, Train Loss: 0.7333 Train metric: 0.7096 Valid Metrics: 0.7127 Total Loss: 1331.6660 Loss.item(): 0.7726848721504211\n",
      "Epoch: 1/1, Train Loss: 0.7253 Train metric: 0.7123 Valid Metrics: 0.7153 Total Loss: 1317.1888 Loss.item(): 0.7637878060340881\n",
      "Epoch: 1/1, Train Loss: 0.7186 Train metric: 0.7142 Valid Metrics: 0.7164 Total Loss: 1304.9935 Loss.item(): 0.7560100555419922\n",
      "Epoch: 1/1, Train Loss: 0.7129 Train metric: 0.7157 Valid Metrics: 0.7176 Total Loss: 1294.5368 Loss.item(): 0.7490865588188171\n",
      "Epoch: 1/1, Train Loss: 0.7078 Train metric: 0.7170 Valid Metrics: 0.7189 Total Loss: 1285.4234 Loss.item(): 0.7428101897239685\n",
      "Epoch: 1/1, Train Loss: 0.7034 Train metric: 0.7183 Valid Metrics: 0.7204 Total Loss: 1277.3621 Loss.item(): 0.737043023109436\n",
      "Epoch: 1/1, Train Loss: 0.6994 Train metric: 0.7194 Valid Metrics: 0.7214 Total Loss: 1270.1364 Loss.item(): 0.7316873073577881\n",
      "Epoch: 1/1, Train Loss: 0.6958 Train metric: 0.7203 Valid Metrics: 0.7222 Total Loss: 1263.5841 Loss.item(): 0.7266555428504944\n",
      "Epoch: 1/1, Train Loss: 0.6925 Train metric: 0.7212 Valid Metrics: 0.7229 Total Loss: 1257.5824 Loss.item(): 0.7218976616859436\n",
      "Epoch: 1/1, Train Loss: 0.6894 Train metric: 0.7220 Valid Metrics: 0.7238 Total Loss: 1252.0370 Loss.item(): 0.7173830270767212\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2026-01-09 18:46:51,598] Trial 5 finished with value: 0.7242732644081116 and parameters: {'learning_rate': 0.000531963670579898, 'n_layers': 1, 'n_hidden_neurons': 147}. Best is trial 1 with value: 0.8903117179870605.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1/1, Train Loss: 0.6866 Train metric: 0.7226 Valid Metrics: 0.7243 Total Loss: 1246.8748 Loss.item(): 0.7130694389343262\n",
      "Epoch: 1/1, Train Loss: 1.2191 Train metric: 0.5381 Valid Metrics: 0.6123 Total Loss: 2213.9545 Loss.item(): 1.094815731048584\n",
      "Epoch: 1/1, Train Loss: 0.8995 Train metric: 0.6364 Valid Metrics: 0.6554 Total Loss: 1633.5654 Loss.item(): 0.9045801758766174\n",
      "Epoch: 1/1, Train Loss: 0.7865 Train metric: 0.6706 Valid Metrics: 0.6839 Total Loss: 1428.2862 Loss.item(): 0.8131862878799438\n",
      "Epoch: 1/1, Train Loss: 0.7387 Train metric: 0.6934 Valid Metrics: 0.6993 Total Loss: 1341.4843 Loss.item(): 0.752269446849823\n",
      "Epoch: 1/1, Train Loss: 0.7099 Train metric: 0.7058 Valid Metrics: 0.7105 Total Loss: 1289.1963 Loss.item(): 0.7090075612068176\n",
      "Epoch: 1/1, Train Loss: 0.6892 Train metric: 0.7150 Valid Metrics: 0.7184 Total Loss: 1251.5736 Loss.item(): 0.6780322790145874\n",
      "Epoch: 1/1, Train Loss: 0.6732 Train metric: 0.7221 Valid Metrics: 0.7250 Total Loss: 1222.4889 Loss.item(): 0.6556026935577393\n",
      "Epoch: 1/1, Train Loss: 0.6602 Train metric: 0.7276 Valid Metrics: 0.7296 Total Loss: 1198.8787 Loss.item(): 0.6383476257324219\n",
      "Epoch: 1/1, Train Loss: 0.6492 Train metric: 0.7320 Valid Metrics: 0.7334 Total Loss: 1178.9615 Loss.item(): 0.624272346496582\n",
      "Epoch: 1/1, Train Loss: 0.6397 Train metric: 0.7359 Valid Metrics: 0.7375 Total Loss: 1161.6690 Loss.item(): 0.6121940612792969\n",
      "Epoch: 1/1, Train Loss: 0.6312 Train metric: 0.7397 Valid Metrics: 0.7418 Total Loss: 1146.3001 Loss.item(): 0.6013078689575195\n",
      "Epoch: 1/1, Train Loss: 0.6236 Train metric: 0.7429 Valid Metrics: 0.7447 Total Loss: 1132.4368 Loss.item(): 0.5917262434959412\n",
      "Epoch: 1/1, Train Loss: 0.6166 Train metric: 0.7457 Valid Metrics: 0.7477 Total Loss: 1119.7913 Loss.item(): 0.5831174850463867\n",
      "Epoch: 1/1, Train Loss: 0.6102 Train metric: 0.7481 Valid Metrics: 0.7497 Total Loss: 1108.1869 Loss.item(): 0.5754870176315308\n",
      "Epoch: 1/1, Train Loss: 0.6044 Train metric: 0.7502 Valid Metrics: 0.7518 Total Loss: 1097.5558 Loss.item(): 0.5680809617042542\n",
      "Epoch: 1/1, Train Loss: 0.5989 Train metric: 0.7525 Valid Metrics: 0.7539 Total Loss: 1087.6247 Loss.item(): 0.5611644387245178\n",
      "Epoch: 1/1, Train Loss: 0.5937 Train metric: 0.7543 Valid Metrics: 0.7562 Total Loss: 1078.2095 Loss.item(): 0.5548692345619202\n",
      "Epoch: 1/1, Train Loss: 0.5888 Train metric: 0.7564 Valid Metrics: 0.7582 Total Loss: 1069.2478 Loss.item(): 0.5490219593048096\n",
      "Epoch: 1/1, Train Loss: 0.5841 Train metric: 0.7580 Valid Metrics: 0.7601 Total Loss: 1060.6937 Loss.item(): 0.543318510055542\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2026-01-09 18:48:26,359] Trial 6 finished with value: 0.7613294124603271 and parameters: {'learning_rate': 0.0005924645281328737, 'n_layers': 5, 'n_hidden_neurons': 176}. Best is trial 1 with value: 0.8903117179870605.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1/1, Train Loss: 0.5796 Train metric: 0.7596 Valid Metrics: 0.7613 Total Loss: 1052.4674 Loss.item(): 0.5384606719017029\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2026-01-09 18:48:30,447] Trial 7 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1/1, Train Loss: 1.8352 Train metric: 0.3186 Valid Metrics: 0.4148 Total Loss: 3332.8004 Loss.item(): 1.6880027055740356\n",
      "Epoch: 1/1, Train Loss: 0.6151 Train metric: 0.7381 Valid Metrics: 0.7523 Total Loss: 1117.0456 Loss.item(): 0.5107054710388184\n",
      "Epoch: 1/1, Train Loss: 0.5497 Train metric: 0.7620 Valid Metrics: 0.7665 Total Loss: 998.3174 Loss.item(): 0.47460365295410156\n",
      "Epoch: 1/1, Train Loss: 0.5290 Train metric: 0.7698 Valid Metrics: 0.7704 Total Loss: 960.6778 Loss.item(): 0.47202277183532715\n",
      "Epoch: 1/1, Train Loss: 0.5204 Train metric: 0.7739 Valid Metrics: 0.7743 Total Loss: 945.0767 Loss.item(): 0.4709990918636322\n",
      "Epoch: 1/1, Train Loss: 0.5160 Train metric: 0.7757 Valid Metrics: 0.7785 Total Loss: 937.0778 Loss.item(): 0.4651038646697998\n",
      "Epoch: 1/1, Train Loss: 0.5111 Train metric: 0.7781 Valid Metrics: 0.7797 Total Loss: 928.1360 Loss.item(): 0.47053030133247375\n",
      "Epoch: 1/1, Train Loss: 0.5065 Train metric: 0.7806 Valid Metrics: 0.7811 Total Loss: 919.8783 Loss.item(): 0.47080859541893005\n",
      "Epoch: 1/1, Train Loss: 0.5018 Train metric: 0.7826 Valid Metrics: 0.7825 Total Loss: 911.2999 Loss.item(): 0.46831461787223816\n",
      "Epoch: 1/1, Train Loss: 0.4992 Train metric: 0.7833 Valid Metrics: 0.7826 Total Loss: 906.5270 Loss.item(): 0.45963066816329956\n",
      "Epoch: 1/1, Train Loss: 0.4973 Train metric: 0.7847 Valid Metrics: 0.7837 Total Loss: 903.1363 Loss.item(): 0.4579029083251953\n",
      "Epoch: 1/1, Train Loss: 0.4959 Train metric: 0.7854 Valid Metrics: 0.7828 Total Loss: 900.5207 Loss.item(): 0.45188912749290466\n",
      "Epoch: 1/1, Train Loss: 0.4942 Train metric: 0.7864 Valid Metrics: 0.7822 Total Loss: 897.4031 Loss.item(): 0.45691749453544617\n",
      "Epoch: 1/1, Train Loss: 0.4931 Train metric: 0.7873 Valid Metrics: 0.7816 Total Loss: 895.5364 Loss.item(): 0.4593867361545563\n",
      "Epoch: 1/1, Train Loss: 0.4920 Train metric: 0.7878 Valid Metrics: 0.7834 Total Loss: 893.4232 Loss.item(): 0.45837682485580444\n",
      "Epoch: 1/1, Train Loss: 0.4905 Train metric: 0.7888 Valid Metrics: 0.7827 Total Loss: 890.6705 Loss.item(): 0.44566836953163147\n",
      "Epoch: 1/1, Train Loss: 0.4894 Train metric: 0.7892 Valid Metrics: 0.7842 Total Loss: 888.7132 Loss.item(): 0.46220189332962036\n",
      "Epoch: 1/1, Train Loss: 0.4878 Train metric: 0.7898 Valid Metrics: 0.7847 Total Loss: 885.7925 Loss.item(): 0.46271446347236633\n",
      "Epoch: 1/1, Train Loss: 0.4862 Train metric: 0.7908 Valid Metrics: 0.7861 Total Loss: 882.8509 Loss.item(): 0.46354466676712036\n",
      "Epoch: 1/1, Train Loss: 0.4849 Train metric: 0.7915 Valid Metrics: 0.7884 Total Loss: 880.5271 Loss.item(): 0.4630610942840576\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2026-01-09 18:49:48,635] Trial 8 finished with value: 0.7884373664855957 and parameters: {'learning_rate': 0.723817198715453, 'n_layers': 1, 'n_hidden_neurons': 37}. Best is trial 1 with value: 0.8903117179870605.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1/1, Train Loss: 0.4837 Train metric: 0.7926 Valid Metrics: 0.7876 Total Loss: 878.3201 Loss.item(): 0.46785929799079895\n",
      "Epoch: 1/1, Train Loss: 0.5778 Train metric: 0.7540 Valid Metrics: 0.7916 Total Loss: 1049.2761 Loss.item(): 0.42991164326667786\n",
      "Epoch: 1/1, Train Loss: 0.4594 Train metric: 0.8056 Valid Metrics: 0.8218 Total Loss: 834.3017 Loss.item(): 0.38393089175224304\n",
      "Epoch: 1/1, Train Loss: 0.4133 Train metric: 0.8269 Valid Metrics: 0.8378 Total Loss: 750.5589 Loss.item(): 0.3615058362483978\n",
      "Epoch: 1/1, Train Loss: 0.3845 Train metric: 0.8397 Valid Metrics: 0.8460 Total Loss: 698.2707 Loss.item(): 0.3287977874279022\n",
      "Epoch: 1/1, Train Loss: 0.3643 Train metric: 0.8487 Valid Metrics: 0.8510 Total Loss: 661.6439 Loss.item(): 0.3366223871707916\n",
      "Epoch: 1/1, Train Loss: 0.3489 Train metric: 0.8555 Valid Metrics: 0.8567 Total Loss: 633.5183 Loss.item(): 0.32302919030189514\n",
      "Epoch: 1/1, Train Loss: 0.3363 Train metric: 0.8613 Valid Metrics: 0.8602 Total Loss: 610.7516 Loss.item(): 0.32323262095451355\n",
      "Epoch: 1/1, Train Loss: 0.3254 Train metric: 0.8661 Valid Metrics: 0.8650 Total Loss: 591.0044 Loss.item(): 0.32037150859832764\n",
      "Epoch: 1/1, Train Loss: 0.3160 Train metric: 0.8704 Valid Metrics: 0.8674 Total Loss: 573.9242 Loss.item(): 0.3056415021419525\n",
      "Epoch: 1/1, Train Loss: 0.3087 Train metric: 0.8734 Valid Metrics: 0.8719 Total Loss: 560.6477 Loss.item(): 0.28518351912498474\n",
      "Epoch: 1/1, Train Loss: 0.3019 Train metric: 0.8766 Valid Metrics: 0.8762 Total Loss: 548.2089 Loss.item(): 0.2925274670124054\n",
      "Epoch: 1/1, Train Loss: 0.2963 Train metric: 0.8792 Valid Metrics: 0.8769 Total Loss: 538.0976 Loss.item(): 0.2831273376941681\n",
      "Epoch: 1/1, Train Loss: 0.2913 Train metric: 0.8810 Valid Metrics: 0.8781 Total Loss: 528.9350 Loss.item(): 0.2759853005409241\n",
      "Epoch: 1/1, Train Loss: 0.2870 Train metric: 0.8830 Valid Metrics: 0.8785 Total Loss: 521.2751 Loss.item(): 0.2668965458869934\n",
      "Epoch: 1/1, Train Loss: 0.2858 Train metric: 0.8839 Valid Metrics: 0.8801 Total Loss: 519.0098 Loss.item(): 0.27071434259414673\n",
      "Epoch: 1/1, Train Loss: 0.2809 Train metric: 0.8853 Valid Metrics: 0.8814 Total Loss: 510.1148 Loss.item(): 0.2524559199810028\n",
      "Epoch: 1/1, Train Loss: 0.2766 Train metric: 0.8877 Valid Metrics: 0.8826 Total Loss: 502.2854 Loss.item(): 0.23595593869686127\n",
      "Epoch: 1/1, Train Loss: 0.2733 Train metric: 0.8891 Valid Metrics: 0.8833 Total Loss: 496.2514 Loss.item(): 0.2321455478668213\n",
      "Epoch: 1/1, Train Loss: 0.2700 Train metric: 0.8907 Valid Metrics: 0.8849 Total Loss: 490.4074 Loss.item(): 0.2295491099357605\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2026-01-09 18:51:13,658] Trial 9 finished with value: 0.8850622177124023 and parameters: {'learning_rate': 0.37939618915180745, 'n_layers': 2, 'n_hidden_neurons': 93}. Best is trial 1 with value: 0.8903117179870605.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1/1, Train Loss: 0.2673 Train metric: 0.8917 Valid Metrics: 0.8851 Total Loss: 485.4479 Loss.item(): 0.21110489964485168\n"
     ]
    }
   ],
   "source": [
    "torch.manual_seed(42)\n",
    "sampler = optuna.samplers.TPESampler(42)\n",
    "pruner = optuna.pruners.MedianPruner()\n",
    "study = optuna.create_study(direction=\"maximize\", sampler=sampler, pruner=pruner)\n",
    "study.optimize(objective, n_trials = 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "id": "53587b37",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1/50, Train Loss: 0.6183 Train metric: 0.7378 Valid Metrics: 0.7804 Total Loss: 1122.7506 Loss.item(): 0.4630967974662781\n",
      "Epoch: 2/50, Train Loss: 0.4905 Train metric: 0.7913 Valid Metrics: 0.8071 Total Loss: 890.7216 Loss.item(): 0.4119083881378174\n",
      "Epoch: 3/50, Train Loss: 0.4366 Train metric: 0.8170 Valid Metrics: 0.8259 Total Loss: 792.8174 Loss.item(): 0.3939302861690521\n",
      "Epoch: 4/50, Train Loss: 0.4013 Train metric: 0.8329 Valid Metrics: 0.8398 Total Loss: 728.7733 Loss.item(): 0.39695993065834045\n",
      "Epoch: 5/50, Train Loss: 0.3769 Train metric: 0.8437 Valid Metrics: 0.8493 Total Loss: 684.3770 Loss.item(): 0.3961508572101593\n",
      "Epoch: 6/50, Train Loss: 0.3574 Train metric: 0.8528 Valid Metrics: 0.8522 Total Loss: 649.1121 Loss.item(): 0.3849705457687378\n",
      "Epoch: 7/50, Train Loss: 0.3415 Train metric: 0.8593 Valid Metrics: 0.8565 Total Loss: 620.0989 Loss.item(): 0.3624454140663147\n",
      "Epoch: 8/50, Train Loss: 0.3279 Train metric: 0.8652 Valid Metrics: 0.8634 Total Loss: 595.4455 Loss.item(): 0.3348224461078644\n",
      "Epoch: 9/50, Train Loss: 0.3162 Train metric: 0.8705 Valid Metrics: 0.8664 Total Loss: 574.1583 Loss.item(): 0.3213696777820587\n",
      "Epoch: 10/50, Train Loss: 0.3064 Train metric: 0.8752 Valid Metrics: 0.8718 Total Loss: 556.3897 Loss.item(): 0.320308655500412\n",
      "Epoch: 11/50, Train Loss: 0.2974 Train metric: 0.8790 Valid Metrics: 0.8733 Total Loss: 540.0849 Loss.item(): 0.3077808916568756\n",
      "Epoch: 12/50, Train Loss: 0.2898 Train metric: 0.8823 Valid Metrics: 0.8750 Total Loss: 526.3217 Loss.item(): 0.29645994305610657\n",
      "Epoch: 13/50, Train Loss: 0.2828 Train metric: 0.8853 Valid Metrics: 0.8765 Total Loss: 513.5410 Loss.item(): 0.2785162031650543\n",
      "Epoch: 14/50, Train Loss: 0.2768 Train metric: 0.8876 Valid Metrics: 0.8781 Total Loss: 502.7409 Loss.item(): 0.280169814825058\n",
      "Epoch: 15/50, Train Loss: 0.2708 Train metric: 0.8905 Valid Metrics: 0.8832 Total Loss: 491.7125 Loss.item(): 0.26975393295288086\n",
      "Epoch: 16/50, Train Loss: 0.2655 Train metric: 0.8923 Valid Metrics: 0.8844 Total Loss: 482.1078 Loss.item(): 0.26274317502975464\n",
      "Epoch: 17/50, Train Loss: 0.2602 Train metric: 0.8947 Valid Metrics: 0.8886 Total Loss: 472.5276 Loss.item(): 0.2465018481016159\n",
      "Epoch: 18/50, Train Loss: 0.2558 Train metric: 0.8964 Valid Metrics: 0.8904 Total Loss: 464.4647 Loss.item(): 0.23461340367794037\n",
      "Epoch: 19/50, Train Loss: 0.2517 Train metric: 0.8984 Valid Metrics: 0.8914 Total Loss: 457.1652 Loss.item(): 0.2190687209367752\n",
      "Epoch: 20/50, Train Loss: 0.2478 Train metric: 0.8993 Valid Metrics: 0.8911 Total Loss: 450.0141 Loss.item(): 0.21474610269069672\n",
      "Epoch: 21/50, Train Loss: 0.2442 Train metric: 0.9013 Valid Metrics: 0.8911 Total Loss: 443.4672 Loss.item(): 0.2092203050851822\n",
      "Epoch: 22/50, Train Loss: 0.2403 Train metric: 0.9027 Valid Metrics: 0.8950 Total Loss: 436.3430 Loss.item(): 0.20824038982391357\n",
      "Epoch: 23/50, Train Loss: 0.2379 Train metric: 0.9036 Valid Metrics: 0.8937 Total Loss: 431.9367 Loss.item(): 0.21810461580753326\n",
      "Epoch: 24/50, Train Loss: 0.2349 Train metric: 0.9049 Valid Metrics: 0.8951 Total Loss: 426.5567 Loss.item(): 0.2227664440870285\n",
      "Epoch: 25/50, Train Loss: 0.2315 Train metric: 0.9065 Valid Metrics: 0.8945 Total Loss: 420.4437 Loss.item(): 0.21052157878875732\n",
      "Epoch: 26/50, Train Loss: 0.2291 Train metric: 0.9073 Valid Metrics: 0.8958 Total Loss: 416.0811 Loss.item(): 0.21257396042346954\n",
      "Epoch: 27/50, Train Loss: 0.2274 Train metric: 0.9083 Valid Metrics: 0.8962 Total Loss: 412.9880 Loss.item(): 0.21996049582958221\n",
      "Epoch: 28/50, Train Loss: 0.2244 Train metric: 0.9093 Valid Metrics: 0.8955 Total Loss: 407.4951 Loss.item(): 0.21385692059993744\n",
      "Epoch: 29/50, Train Loss: 0.2219 Train metric: 0.9105 Valid Metrics: 0.8970 Total Loss: 402.9813 Loss.item(): 0.19028182327747345\n",
      "Epoch: 30/50, Train Loss: 0.2200 Train metric: 0.9115 Valid Metrics: 0.9002 Total Loss: 399.5934 Loss.item(): 0.20252612233161926\n",
      "Epoch: 31/50, Train Loss: 0.2189 Train metric: 0.9119 Valid Metrics: 0.8960 Total Loss: 397.4372 Loss.item(): 0.22774352133274078\n",
      "Epoch: 32/50, Train Loss: 0.2167 Train metric: 0.9128 Valid Metrics: 0.8976 Total Loss: 393.4518 Loss.item(): 0.21242496371269226\n",
      "Epoch: 33/50, Train Loss: 0.2151 Train metric: 0.9134 Valid Metrics: 0.9027 Total Loss: 390.6713 Loss.item(): 0.1904689371585846\n",
      "Epoch: 34/50, Train Loss: 0.2134 Train metric: 0.9141 Valid Metrics: 0.9031 Total Loss: 387.5620 Loss.item(): 0.18973292410373688\n",
      "Epoch: 35/50, Train Loss: 0.2117 Train metric: 0.9155 Valid Metrics: 0.9058 Total Loss: 384.4371 Loss.item(): 0.1675010472536087\n",
      "Epoch: 36/50, Train Loss: 0.2100 Train metric: 0.9158 Valid Metrics: 0.9031 Total Loss: 381.4060 Loss.item(): 0.17853401601314545\n",
      "Epoch: 37/50, Train Loss: 0.2089 Train metric: 0.9161 Valid Metrics: 0.9065 Total Loss: 379.3999 Loss.item(): 0.19110825657844543\n",
      "Epoch: 38/50, Train Loss: 0.2074 Train metric: 0.9170 Valid Metrics: 0.9069 Total Loss: 376.6865 Loss.item(): 0.18001052737236023\n",
      "Epoch: 39/50, Train Loss: 0.2066 Train metric: 0.9169 Valid Metrics: 0.9080 Total Loss: 375.1619 Loss.item(): 0.18848755955696106\n",
      "Epoch: 40/50, Train Loss: 0.2064 Train metric: 0.9174 Valid Metrics: 0.9094 Total Loss: 374.7894 Loss.item(): 0.16882599890232086\n",
      "Epoch: 41/50, Train Loss: 0.2043 Train metric: 0.9180 Valid Metrics: 0.9095 Total Loss: 370.9257 Loss.item(): 0.1718863993883133\n",
      "Epoch: 42/50, Train Loss: 0.2032 Train metric: 0.9183 Valid Metrics: 0.9089 Total Loss: 368.9912 Loss.item(): 0.18659231066703796\n",
      "Epoch: 43/50, Train Loss: 0.2022 Train metric: 0.9187 Valid Metrics: 0.9092 Total Loss: 367.1201 Loss.item(): 0.1830216944217682\n",
      "Epoch: 44/50, Train Loss: 0.2012 Train metric: 0.9190 Valid Metrics: 0.9094 Total Loss: 365.2901 Loss.item(): 0.1776856631040573\n",
      "Epoch: 45/50, Train Loss: 0.2006 Train metric: 0.9196 Valid Metrics: 0.9116 Total Loss: 364.2540 Loss.item(): 0.19790469110012054\n",
      "Epoch: 46/50, Train Loss: 0.1991 Train metric: 0.9204 Valid Metrics: 0.9127 Total Loss: 361.5509 Loss.item(): 0.17912785708904266\n",
      "Epoch: 47/50, Train Loss: 0.1982 Train metric: 0.9206 Valid Metrics: 0.9097 Total Loss: 359.9005 Loss.item(): 0.17871630191802979\n",
      "Epoch: 48/50, Train Loss: 0.1978 Train metric: 0.9209 Valid Metrics: 0.9088 Total Loss: 359.2179 Loss.item(): 0.17551471292972565\n",
      "Epoch: 49/50, Train Loss: 0.1967 Train metric: 0.9211 Valid Metrics: 0.9088 Total Loss: 357.2964 Loss.item(): 0.17418693006038666\n",
      "Epoch: 50/50, Train Loss: 0.1956 Train metric: 0.9213 Valid Metrics: 0.9120 Total Loss: 355.2284 Loss.item(): 0.14777356386184692\n"
     ]
    }
   ],
   "source": [
    "tuned_model = CovTypeClassifier(n_inputs=54, num_hidden_neurons=[study.best_params[\"n_hidden_neurons\"]] * study.best_params[\"n_layers\"], n_classes=7).to(device)\n",
    "optimizer = torch.optim.SGD(tuned_model.parameters(), lr = study.best_params[\"learning_rate\"])\n",
    "xentropy = nn.CrossEntropyLoss()\n",
    "accuracy = torchmetrics.Accuracy(task = \"multiclass\", num_classes=7).to(device)\n",
    "tuned_history = train2(tuned_model, optimizer, xentropy, accuracy, train_loader, valid_loader, n_epochs=50)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "id": "dd3bc301",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([-1.0704,  2.1556, -5.7544, -4.8794,  7.8187, -3.6812,  0.4009],\n",
       "       device='cuda:0', grad_fn=<ViewBackward0>)"
      ]
     },
     "execution_count": 136,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_new = X_tensor[0]\n",
    "tuned_model(X_new.to(device))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "id": "d9660e91",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_results = evaluate_tm(tuned_model, test_loader, accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "id": "d09aab23",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.9126, device='cuda:0')"
      ]
     },
     "execution_count": 138,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_results"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
